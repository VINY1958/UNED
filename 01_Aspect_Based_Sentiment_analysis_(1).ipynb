{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Viny2030/UNED/blob/main/01_Aspect_Based_Sentiment_analysis_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU89uPP_WlbF"
      },
      "source": [
        "In this notebook we will deomonstrate aspect based sentiment analysis using [Varder](https://github.com/cjhutto/vaderSentiment) and [Stanford Core NLP](https://stanfordnlp.github.io/CoreNLP/index.html).<br>\n",
        "<br>**VADER Sentiment Analysis**: VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains.(source:[github](https://github.com/cjhutto/vaderSentiment))<br>\n",
        "Stanford NLP have a live demo of aspect based sentiment analysis [here](http://nlp.stanford.edu:8080/sentiment/rntnDemo.html).<br><br>\n",
        "**Stanford Core NLP**: \"Most sentiment prediction systems work just by looking at words in isolation, giving positive points for positive words and negative points for negative words and then summing up these points. That way, the order of words is ignored and important information is lost. In constrast, our new deep learning model actually builds up a representation of whole sentences based on the sentence structure. It computes the sentiment based on how words compose the meaning of longer phrases. This way, the model is not as easily fooled as previous models.\"(source: [Stanford Core NLP](https://nlp.stanford.edu/sentiment/index.html).)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este cuaderno, demostraremos el análisis de sentimientos basado en aspectos utilizando Varder y Stanford Core NLP.\n",
        "\n",
        "Análisis de sentimientos VADER: VADER (Valence Aware Dictionary and sEntiment Reasoner) es una herramienta de análisis de sentimientos basada en reglas y léxicos que está específicamente adaptada a los sentimientos expresados ​​en las redes sociales y funciona bien con textos de otros dominios. (Fuente: github)\n",
        "Stanford NLP tiene una demostración en vivo del análisis de sentimientos basado en aspectos aquí.\n",
        "\n",
        "Stanford Core NLP: \"La mayoría de los sistemas de predicción de sentimientos funcionan simplemente observando las palabras de forma aislada, dando puntos positivos para las palabras positivas y puntos negativos para las palabras negativas y luego sumando estos puntos. De esa manera, se ignora el orden de las palabras y se pierde información importante. En cambio, nuestro nuevo modelo de aprendizaje profundo en realidad crea una representación de oraciones completas en función de la estructura de la oración. Calcula el sentimiento en función de cómo las palabras componen el significado de frases más largas. De esta manera, el modelo no se engaña tan fácilmente como los modelos anteriores\". (Fuente: Stanford Core NLP).\n"
      ],
      "metadata": {
        "id": "XcDNyKW_rpeL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "scrolled": true,
        "id": "LH1Ii32aWlbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654fa78b-ced7-4eea-935d-6d586b927016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install vaderSentiment\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycorenlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtVWIsHRrtmT",
        "outputId": "04f9af24-06c2-4cec-a94c-722a832eed53"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycorenlp in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pycorenlp) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pycorenlp) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pycorenlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pycorenlp) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pycorenlp) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy2k75eZWlbN"
      },
      "source": [
        "### Importing the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xOFRT7mLWlbO",
        "outputId": "c40326df-1509-493f-e227-b27e3b0585de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import re\n",
        "import string\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
        "\n",
        "from pycorenlp import StanfordCoreNLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSAp58rMWlbS"
      },
      "source": [
        "Lets analyze these three sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1eS1F1lKWlbS"
      },
      "outputs": [],
      "source": [
        "positive = \"This fried chicken tastes very good. It is juicy and perfectly cooked.\"\n",
        "negative = \"This fried chicken tasted bad. It is dry and overcooked.\"\n",
        "ambiguous = \"Except the amazing fried chicken everything else at the restaurant tastes very bad.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uw6yrLrWlbT"
      },
      "source": [
        "### VarderSentiment\n",
        "It scores from -1 to 1. -1 being negative and 1 being positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XhwA-7QMWlbU"
      },
      "outputs": [],
      "source": [
        "def sentiment_analyzer_scores(text):\n",
        "    sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "    score = sentiment_analyzer.polarity_scores(text)\n",
        "    pprint(text)\n",
        "    pprint(score)\n",
        "    print(\"-\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UsCmmYtoWlbW",
        "outputId": "60246ac2-e5f4-4322-cb4a-05f37f503f3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive:\n",
            "'This fried chicken tastes very good. It is juicy and perfectly cooked.'\n",
            "{'compound': 0.8122, 'neg': 0.0, 'neu': 0.575, 'pos': 0.425}\n",
            "------------------------------\n",
            "Negative:\n",
            "'This fried chicken tasted bad. It is dry and overcooked.'\n",
            "{'compound': -0.5423, 'neg': 0.28, 'neu': 0.72, 'pos': 0.0}\n",
            "------------------------------\n",
            "Ambiguous:\n",
            "('Except the amazing fried chicken everything else at the restaurant tastes '\n",
            " 'very bad.')\n",
            "{'compound': 0.0018, 'neg': 0.204, 'neu': 0.592, 'pos': 0.204}\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(\"Positive:\")\n",
        "sentiment_analyzer_scores(positive)\n",
        "\n",
        "print(\"Negative:\")\n",
        "sentiment_analyzer_scores(negative)\n",
        "\n",
        "print(\"Ambiguous:\")\n",
        "sentiment_analyzer_scores(ambiguous)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpXbSpVlWlbX"
      },
      "source": [
        "As expected the sentiment analyzer performed well on the positive and negative case. When taking into consideration the ambiguous sentence, it calculated the compound sentiment to be close to 0, i.e, neutral.<br>\n",
        "But it seems to be a negative comment."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como era de esperar, el analizador de sentimientos funcionó bien tanto en el caso positivo como en el negativo. Al tomar en cuenta la oración ambigua, calculó que el sentimiento compuesto era cercano a 0, es decir, neutral.\n",
        "Pero parece ser un comentario negativo."
      ],
      "metadata": {
        "id": "iJPxPUtEr5ci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zMiMQxOvWlbY"
      },
      "outputs": [],
      "source": [
        "def get_word_sentiment(text):\n",
        "    sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    tokenized_text = nltk.word_tokenize(text)\n",
        "\n",
        "    positive_words=[]\n",
        "    neutral_words=[]\n",
        "    negative_words=[]\n",
        "    for word in tokenized_text:\n",
        "        if (sentiment_analyzer.polarity_scores(word)['compound']) >= 0.1:\n",
        "            positive_words.append(word)\n",
        "        elif (sentiment_analyzer.polarity_scores(word)['compound']) <= -0.1:\n",
        "            negative_words.append(word)\n",
        "        else:\n",
        "            neutral_words.append(word)\n",
        "    print(text)\n",
        "    print('Positive:',positive_words)\n",
        "    print('Negative:',negative_words)\n",
        "    print('Neutral:',neutral_words)\n",
        "    print(\"-\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxy-6JWLaQNI",
        "outputId": "dc2fbbf6-58d4-47e0-d607-d07d17ba354e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tb4WbjaEWlbZ",
        "outputId": "2ef81655-1e29-4503-efea-d0f925b5e268",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This fried chicken tastes very good. It is juicy and perfectly cooked.\n",
            "Positive: ['good', 'perfectly']\n",
            "Negative: []\n",
            "Neutral: ['This', 'fried', 'chicken', 'tastes', 'very', '.', 'It', 'is', 'juicy', 'and', 'cooked', '.']\n",
            "------------------------------\n",
            "This fried chicken tasted bad. It is dry and overcooked.\n",
            "Positive: []\n",
            "Negative: ['bad']\n",
            "Neutral: ['This', 'fried', 'chicken', 'tasted', '.', 'It', 'is', 'dry', 'and', 'overcooked', '.']\n",
            "------------------------------\n",
            "Except the amazing fried chicken everything else at the restaurant tastes very bad.\n",
            "Positive: ['amazing']\n",
            "Negative: ['bad']\n",
            "Neutral: ['Except', 'the', 'fried', 'chicken', 'everything', 'else', 'at', 'the', 'restaurant', 'tastes', 'very', '.']\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "get_word_sentiment(positive)\n",
        "get_word_sentiment(negative)\n",
        "get_word_sentiment(ambiguous)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEFH9z-CWlbZ"
      },
      "source": [
        "### Stanford Core NLP\n",
        "Before moving on to execute the code we need to start the Stanford Core NLP server on our local machine.<br> To do that follow the steps below (tested on debian should work fine for other distributions too):\n",
        "1. Download the Stanford Core NLP model from [here](https://stanfordnlp.github.io/CoreNLP/#download).\n",
        "2. Unizip the folder\n",
        "3. cd into the folder<br>\n",
        "    ```cd stanford-corenlp-4.0.0/```\n",
        "4. Start the server using this command:<br>\n",
        "    ```java -mx5g -cp \"./*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -timeout 10000```\n",
        "<br><br>\n",
        "If you do not have java installed on your system please install it from the official [Oracle](https://www.oracle.com/in/java/technologies/javase-downloads.html) page.\n",
        "<br><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stanford Core NLP**\n",
        "Antes de ejecutar el código, debemos iniciar el servidor Stanford Core NLP en nuestra máquina local.\n",
        "Para ello, siga los pasos que se indican a continuación (probado en Debian, debería funcionar bien también para otras distribuciones):\n",
        "\n",
        "Descargue el modelo Stanford Core NLP desde aquí.\n",
        "Descomprima la carpeta\n",
        "cd en la carpeta\n",
        "cd stanford-corenlp-4.0.0/\n",
        "Inicie el servidor con este comando:\n",
        "java -mx5g -cp \"./*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -timeout 10000\n",
        "\n",
        "Si no tiene Java instalado en su sistema, instálelo desde la página oficial de Oracle.\n"
      ],
      "metadata": {
        "id": "2pexko5Lr-7J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bQeyC7F0Wlba"
      },
      "outputs": [],
      "source": [
        "nlp = StanfordCoreNLP('http://localhost:9000')\n",
        "\n",
        "def get_sentiment(text):\n",
        "    res = nlp.annotate(text,\n",
        "                       properties={'annotators': 'sentiment',\n",
        "                                   'outputFormat': 'json',\n",
        "                                   'timeout': 1000,\n",
        "                       })\n",
        "    print(text)\n",
        "    print('Sentiment:', res['sentences'][0]['sentiment'])\n",
        "    print('Sentiment score:', res['sentences'][0]['sentimentValue'])\n",
        "    print('Sentiment distribution (0-v. negative, 5-v. positive:', res['sentences'][0]['sentimentDistribution'])\n",
        "    print(\"-\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 10000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRKzHGZtasLm",
        "outputId": "1ac352df-2663-428b-f8be-65c5c6fc0782"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not find or load main class edu.stanford.nlp.pipeline.StanfordCoreNLPServer\n",
            "Caused by: java.lang.ClassNotFoundException: edu.stanford.nlp.pipeline.StanfordCoreNLPServer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "-3R1JTYUbYTK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "33qxk7n7Wlba",
        "outputId": "113e10dd-43a0-4107-cf14-5fc5b72a03df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This fried chicken tastes very good. It is juicy and perfectly cooked.\n",
            "Positive: ['good', 'perfectly']\n",
            "Negative: []\n",
            "Neutral: ['This', 'fried', 'chicken', 'tastes', 'very', '.', 'It', 'is', 'juicy', 'and', 'cooked', '.']\n",
            "------------------------------\n",
            "This fried chicken tasted bad. It is dry and overcooked.\n",
            "Positive: []\n",
            "Negative: ['bad']\n",
            "Neutral: ['This', 'fried', 'chicken', 'tasted', '.', 'It', 'is', 'dry', 'and', 'overcooked', '.']\n",
            "------------------------------\n",
            "Except the amazing fried chicken everything else at the restaurant tastes very bad.\n",
            "Positive: ['amazing']\n",
            "Negative: ['bad']\n",
            "Neutral: ['Except', 'the', 'fried', 'chicken', 'everything', 'else', 'at', 'the', 'restaurant', 'tastes', 'very', '.']\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "get_word_sentiment(positive)\n",
        "get_word_sentiment(negative)\n",
        "get_word_sentiment(ambiguous)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaKFWHheWlbb"
      },
      "source": [
        "Here you see the model successfully predicts the ambigous sentence which the Varder failed to predict correctly.<br>\n",
        "The code in this notebook has been adapted from this [article](https://towardsdatascience.com/sentiment-analysis-beyond-words-6ca17a6c1b54).See below code for colab."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí puede ver que el modelo predice correctamente la oración ambigua que la Orden no pudo predecir correctamente.\n",
        "El código de este cuaderno se ha adaptado de este artículo. Vea el código de colab a continuación."
      ],
      "metadata": {
        "id": "Ds0FQxFXsKPb"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}