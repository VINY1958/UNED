{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Viny2030/UNED/blob/main/103_NLP_Conceptos_spaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeX2u-CUDuIN"
      },
      "source": [
        "# 03 - Conceptos para el Procesamiento del Lenguaje Natural con spaCy\n",
        "\n",
        "* ***spaCy*** es una librería de código abierto en python para el Procesamiento del Lenguaje natural que posee modelos entrenados para varios idiomas, entre ellos el Español.\n",
        "\n",
        "\n",
        "* Es una librería pensada para funcionar en entornos productivos y es una librería con mejor rendimiento que **NLTK**.\n",
        "\n",
        "\n",
        "* Dispone de una web y de una documentación muy buena, incluso se pueden ejecutar ciertos ejemplos en la propia web: https://spacy.io/\n",
        "\n",
        "\n",
        "* Dispone también de un curso online (https://course.spacy.io/) bastante interesante.\n",
        "\n",
        "\n",
        "* Entre otras cosas con ***spaCy*** podemos hacer:\n",
        "    1. Tokenización\n",
        "    2. Lematización\n",
        "    3. Detección de Stop Words\n",
        "    4. Part of Speech (PoS)\n",
        "    5. Named Entity Recognition (NER)\n",
        "\n",
        "\n",
        "* ***spaCy*** puede ser instalado tanto con \"pip\" como con \"conda\" de la siguiente manera respectivamente:\n",
        "\n",
        "```\n",
        ">> pip install spacy\n",
        ">> conda install spacy\n",
        "```\n",
        "\n",
        "\n",
        "* Como se ha comentado anteriormente la ventaja que tiene ***spaCy*** frente a ***NLTK*** en lo que a idiomas se refiere es que permite trabajar con varior idiomas gracias a los modelos que tiene entrenados.\n",
        "\n",
        "\n",
        "* En particular para el Español ***spaCy*** tiene entrenados dos modelos (con Redes Neuronales Convolucionales según su documentación) de pequeño y mediano tamaño con los corpus de **AnCora** (http://clic.ub.edu/corpus/es/ancora) y **WikiNER**.\n",
        "\n",
        "\n",
        "* Estos dos modelos de pequeño y mediano tamaño los podemos encontrar en la web de ***spaCy*** (https://spacy.io/models/es) y son los siguiente:\n",
        "    - es_core_news_md (93 MiB)\n",
        "    - es_core_news_sm (35 MiB)\n",
        "\n",
        "\n",
        "* ***spaCy*** hace uso de estos modelos y tienen que ser descargados, para ello debemos de abrir un terminal en python y ejecutar lo siguiente para descargar el modelo en Español (*NOTA: los que uséis conda, tener activado el entorno*).\n",
        "\n",
        "\n",
        "```\n",
        ">> python3 -m spacy download es\n",
        "```\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/Viny2030/UNED/blob/main/imgs/005_spacy_es_download.png?raw=1\" style=\"width: 500px;\"/>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bynBlmT5DuIW"
      },
      "outputs": [],
      "source": [
        "#!python -m spacy download es"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_ZZBoSiDuIZ"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "# spaCy - Arquitectura:\n",
        "\n",
        "* ***spaCy*** utiliza dos tipos de estructuras (objetos) llamados **Doc** y **Vocab**:\n",
        "<span></span><br><br>\n",
        "    - ***Doc***: Este objeto esta formado por una secuencia de Tokens (objetos de la clase ***Token***).\n",
        "<span></span><br><br>\n",
        "    - ***Vocab***: Este objeto posee un conjunto de Look-up tables (tablas de consulta) que hacen que la información común esté disponible en todos los documentos (Lemas, Stop Words, PoS, etc.).\n",
        "\n",
        "<img src=\"https://github.com/Viny2030/UNED/blob/main/imgs/006_spacy_architecture.png?raw=1\" style=\"width: 600px;\"/>\n",
        "\n",
        "\n",
        "* Una forma sencilla de trabajar con ***spaCy*** es:\n",
        "    1. Cargar un modelo de lenguaje (por ejemplo el Español)\n",
        "    2. Dado un texto plano, crear un objeto de la clase \"Doc\" y pasarle el texto plano. El texto ya quedará tokenizado dentro del objeto \"Doc\".\n",
        "    3. Trabajar sobre las palabras del documento.\n",
        "\n",
        "<hr>\n",
        "\n",
        "\n",
        "\n",
        "# Ejemplos con spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbgCPc98DuIa"
      },
      "source": [
        "## -Tokenización\n",
        "\n",
        "\n",
        "* Divide las cadenas de texto del documento en piezas más pequeñas o tokens.\n",
        "\n",
        "\n",
        "* Pasos:\n",
        "    1. Importar la librería.\n",
        "    2. Cargar un modelo de lenguaje (el Español).\n",
        "    3. Crear un documento (de la clase \"Doc\") pasándole un texto plano.\n",
        "    4. El objeto de la clase \"Doc\" ya esta tokenizado por palabras y podemos iterar sobre él."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92hWw4QWEOtk",
        "outputId": "b04487a2-cb9a-4b09-ae7a-f4b5fada97b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyt_-FFRDuIb",
        "outputId": "d80c6a22-41d6-4bae-95ff-713570c95b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo de dato: <class 'spacy.tokens.doc.Doc'>\n",
            "['Un', 'radar', 'multa', 'a', 'Mariano', '.', 'Rajoy', 'por', 'caminar', 'demasiado', 'rápido']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "doc = nlp(\"Un radar multa a Mariano. Rajoy por caminar demasiado rápido\")\n",
        "print('Tipo de dato: ' + str(type(doc)))\n",
        "print([w.text for w in doc])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tokenizacion input"
      ],
      "metadata": {
        "id": "20NS9XpUFt2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_news_sm"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhot09YCG0II",
        "outputId": "025928aa-8ab6-4c7f-c6e4-af95f502c207"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[38;5;1m✘ No compatible package found for 'en_core_news_sm' (spaCy v3.7.5)\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "input = nlp(\"Jane bought me these books.Jane bought a book for me.She dropped a line to him. Thank you.She sleeps.I sleep a lot.I was born in Madrid.the cat was chased by the dog.I was born in Madrid during 1995.Out of all this , something good will come.Susan left after the rehearsal. She did it well.She sleeps during the morning, but she sleeps.\")\n",
        "print([(w.text, w.pos_) for w in input])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqVUvSDXHO0O",
        "outputId": "290e57ee-1222-40db-fa18-e906ad41d39f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Jane', 'PROPN'), ('bought', 'VERB'), ('me', 'PRON'), ('these', 'DET'), ('books', 'NOUN'), ('.', 'PUNCT'), ('Jane', 'PROPN'), ('bought', 'VERB'), ('a', 'DET'), ('book', 'NOUN'), ('for', 'ADP'), ('me', 'PRON'), ('.', 'PUNCT'), ('She', 'PRON'), ('dropped', 'VERB'), ('a', 'DET'), ('line', 'NOUN'), ('to', 'ADP'), ('him', 'PRON'), ('.', 'PUNCT'), ('Thank', 'VERB'), ('you', 'PRON'), ('.', 'PUNCT'), ('She', 'PRON'), ('sleeps', 'VERB'), ('.', 'PUNCT'), ('I', 'PRON'), ('sleep', 'VERB'), ('a', 'DET'), ('lot', 'NOUN'), ('.', 'PUNCT'), ('I', 'PRON'), ('was', 'AUX'), ('born', 'VERB'), ('in', 'ADP'), ('Madrid.the', 'PROPN'), ('cat', 'NOUN'), ('was', 'AUX'), ('chased', 'VERB'), ('by', 'ADP'), ('the', 'DET'), ('dog', 'NOUN'), ('.', 'PUNCT'), ('I', 'PRON'), ('was', 'AUX'), ('born', 'VERB'), ('in', 'ADP'), ('Madrid', 'PROPN'), ('during', 'ADP'), ('1995.Out', 'NUM'), ('of', 'ADP'), ('all', 'DET'), ('this', 'PRON'), (',', 'PUNCT'), ('something', 'PRON'), ('good', 'ADJ'), ('will', 'AUX'), ('come', 'VERB'), ('.', 'PUNCT'), ('Susan', 'PROPN'), ('left', 'VERB'), ('after', 'ADP'), ('the', 'DET'), ('rehearsal', 'NOUN'), ('.', 'PUNCT'), ('She', 'PRON'), ('did', 'VERB'), ('it', 'PRON'), ('well', 'ADV'), ('.', 'PUNCT'), ('She', 'PRON'), ('sleeps', 'VERB'), ('during', 'ADP'), ('the', 'DET'), ('morning', 'NOUN'), (',', 'PUNCT'), ('but', 'CCONJ'), ('she', 'PRON'), ('sleeps', 'VERB'), ('.', 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenizacion output**"
      ],
      "metadata": {
        "id": "PtewbPJLHhbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n"
      ],
      "metadata": {
        "id": "Duoy02v-HlpW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = '/content/output.txt'\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pCgPb51yIHuz",
        "outputId": "97bd4ca5-b96a-4bf5-c58d-ad816265141e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/output.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNZ7DkiMIK9O",
        "outputId": "6b57ad99-3718-4e95-98b4-a2d499ff11ab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##doc2 = '/content/output.txt'\n",
        "output = nlp(output)\n",
        "print([(w.text, w.pos_) for w in output])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVt15JPrH6rC",
        "outputId": "dbba33e5-d99b-4555-f298-4d5615903997"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('/content', 'PUNCT'), ('/', 'SYM'), ('output.txt', 'X')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "h4vLM-prIXSD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.read_json(\"https://raw.githubusercontent.com/Viny2030/datasets/refs/heads/main/output.json\")"
      ],
      "metadata": {
        "id": "jYJ5q4VSIV3f"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = nlp(output.iloc[:,0].astype(str).str.cat(sep=' '))\n",
        "print([(w.text, w.pos_) for w in output])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOuNSc97IfTf",
        "outputId": "132a7e82-9f44-4ece-a557-c2c808f32e65"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[', 'X'), (\"'\", 'PUNCT'), ('I', 'PRON'), ('was', 'AUX'), ('born', 'VERB'), ('in', 'ADP'), ('Madrid', 'PROPN'), ('.', 'PUNCT'), (\"'\", 'PUNCT'), (',', 'PUNCT'), (\"'\", 'PUNCT'), ('I', 'PRON'), ('was', 'AUX'), ('born', 'VERB'), ('in', 'ADP'), ('Madrid', 'PROPN'), ('during', 'ADP'), ('1995', 'NUM'), ('.', 'PUNCT'), (\"'\", 'PUNCT'), (']', 'PUNCT'), ('NVPN', 'PROPN'), ('2', 'NUM'), ('I', 'PRON'), ('bear', 'VERB'), ('None', 'PROPN'), ('in', 'ADP'), ('CITY', 'PROPN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "herDiUG9DuIe"
      },
      "source": [
        "## -Segmentación\n",
        "\n",
        "\n",
        "* La ***segmentación*** divide las cadenas de texto en frases o párrafos.\n",
        "\n",
        "\n",
        "* Para la segmentación en spaCy hay que usar un componente llamado \"**sentencier**\" que divide los textos por simbolos como puntos, interrogantes, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NWI_bGsDuIf",
        "outputId": "cf3c6348-f060-4527-d5e9-ad62d88d4a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Frase numero 1.', 'Frase número 2?', 'Frase 3']\n"
          ]
        }
      ],
      "source": [
        "from spacy.pipeline import Sentencizer\n",
        "sentencizer = Sentencizer()\n",
        "doc = nlp(\"Frase numero 1. Frase número 2? Frase 3\")\n",
        "print([s.text for s in doc.sents])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**##Segmentacion input**"
      ],
      "metadata": {
        "id": "480VPbOTItxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.pipeline import Sentencizer\n",
        "sentencizer = Sentencizer()\n",
        "input = nlp((\"Jane bought me these books.Jane bought a book for me.She dropped a line to him. Thank you.She sleeps.I sleep a lot.I was born in Madrid.the cat was chased by the dog.I was born in Madrid during 1995.Out of all this , something good will come.Susan left after the rehearsal. She did it well.She sleeps during the morning, but she sleeps.\"))\n",
        "print([s.text for s in input.sents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryKIbLEPI07D",
        "outputId": "ca6e062a-024f-46e2-fef8-86750a0af5cf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Jane bought me these books.', 'Jane bought a book for me.', 'She dropped a line to him.', 'Thank you.', 'She sleeps.', 'I sleep a lot.', 'I was born in Madrid.the cat was chased by the dog.', 'I was born in Madrid during 1995.Out of all this , something good will come.', 'Susan left after the rehearsal.', 'She did it well.', 'She sleeps during the morning, but she sleeps.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**##Segmentacion output**"
      ],
      "metadata": {
        "id": "r6rJ6bXvJDPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.read_json(\"https://raw.githubusercontent.com/Viny2030/datasets/refs/heads/main/output.json\")"
      ],
      "metadata": {
        "id": "nACiNUnvJJmd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = nlp(output.iloc[:,0].astype(str).str.cat(sep=' '))\n",
        "print([s.text for s in output.sents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRfVFwZfJQGU",
        "outputId": "a3fec950-f4b7-44ce-93de-0bbf670f8454"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"['I was born in Madrid.', 'I was born in Madrid during 1995.']\", 'NVPN 2 I bear None in CITY']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMvl2EXdDuIg"
      },
      "source": [
        "## -Stemming\n",
        "\n",
        "* ***Funcionalidad no disponoble en spaCy***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BkyLNh8DuIh"
      },
      "source": [
        "## -Lematización\n",
        "\n",
        "\n",
        "* Proceso lingüístico que sustituye una palabra con forma flexionada (plurales, femeninos, verbos conjugados, etc.) por su lema; es decir, por una palabra válida en el idioma.\n",
        "\n",
        "\n",
        "* ***spaCy*** hace una lematización muy buena en Español.\n",
        "\n",
        "\n",
        "* Los objetos de la clase ***Token*** tienen la propiedad (o atributo) ***lema_*** que nos devuelve el lema del token (o la palabra)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmQeSnxrDuIi",
        "outputId": "61fe4c3e-a1fe-433a-b6d1-d8f5aa28d9bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unos - Unos\n",
            "radares - radare\n",
            "multan - multan\n",
            "a - a\n",
            "Mariano - Mariano\n",
            "Rajoy - Rajoy\n",
            "por - por\n",
            "ir - ir\n",
            "caminando - caminando\n",
            "demasiados - demasiado\n",
            "rápidos - rápido\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(\"Unos radares multan a Mariano Rajoy por ir caminando demasiados rápidos\")\n",
        "for word in doc:\n",
        "    print(word.text + ' - ' + word.lemma_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **##Lematizacion input**"
      ],
      "metadata": {
        "id": "FzEWcNRCJbMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = nlp((\"Jane bought me these books.Jane bought a book for me.She dropped a line to him. Thank you.She sleeps.I sleep a lot.I was born in Madrid.the cat was chased by the dog.I was born in Madrid during 1995.Out of all this , something good will come.Susan left after the rehearsal. She did it well.She sleeps during the morning, but she sleeps.\"))\n",
        "for word in input:\n",
        "    print(word.text + ' - ' + word.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZFOuibTJg5R",
        "outputId": "a7e57bc9-cffd-44fd-cecd-f92ee64e904a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jane - Jane\n",
            "bought - buy\n",
            "me - I\n",
            "these - these\n",
            "books - book\n",
            ". - .\n",
            "Jane - Jane\n",
            "bought - buy\n",
            "a - a\n",
            "book - book\n",
            "for - for\n",
            "me - I\n",
            ". - .\n",
            "She - she\n",
            "dropped - drop\n",
            "a - a\n",
            "line - line\n",
            "to - to\n",
            "him - he\n",
            ". - .\n",
            "Thank - thank\n",
            "you - you\n",
            ". - .\n",
            "She - she\n",
            "sleeps - sleep\n",
            ". - .\n",
            "I - I\n",
            "sleep - sleep\n",
            "a - a\n",
            "lot - lot\n",
            ". - .\n",
            "I - I\n",
            "was - be\n",
            "born - bear\n",
            "in - in\n",
            "Madrid.the - Madrid.the\n",
            "cat - cat\n",
            "was - be\n",
            "chased - chase\n",
            "by - by\n",
            "the - the\n",
            "dog - dog\n",
            ". - .\n",
            "I - I\n",
            "was - be\n",
            "born - bear\n",
            "in - in\n",
            "Madrid - Madrid\n",
            "during - during\n",
            "1995.Out - 1995.out\n",
            "of - of\n",
            "all - all\n",
            "this - this\n",
            ", - ,\n",
            "something - something\n",
            "good - good\n",
            "will - will\n",
            "come - come\n",
            ". - .\n",
            "Susan - Susan\n",
            "left - leave\n",
            "after - after\n",
            "the - the\n",
            "rehearsal - rehearsal\n",
            ". - .\n",
            "She - she\n",
            "did - do\n",
            "it - it\n",
            "well - well\n",
            ". - .\n",
            "She - she\n",
            "sleeps - sleep\n",
            "during - during\n",
            "the - the\n",
            "morning - morning\n",
            ", - ,\n",
            "but - but\n",
            "she - she\n",
            "sleeps - sleep\n",
            ". - .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **lematizacion output**"
      ],
      "metadata": {
        "id": "S5F0t7JdJ2m-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "r-_rBWC5D9KL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.read_json(\"https://raw.githubusercontent.com/Viny2030/datasets/refs/heads/main/output.json\")"
      ],
      "metadata": {
        "id": "pbNRQXonJ6mb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load data from JSON file into a pandas DataFrame\n",
        "df = pd.read_json(\"https://raw.githubusercontent.com/Viny2030/datasets/refs/heads/main/output.json\")\n",
        "\n",
        "# Process the text data from the DataFrame using spaCy\n",
        "# Extract the text data from the first column, convert it to string type, and join it into a single string\n",
        "text_data = df.iloc[:, 0].astype(str).str.cat(sep=' ')\n",
        "\n",
        "# Process the text using spaCy\n",
        "output = nlp(text_data)\n",
        "\n",
        "# Iterate through the tokens and print the text and lemma\n",
        "for word in output:\n",
        "    print(word.text + ' - ' + word.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5401fDRF81Q",
        "outputId": "0c3b39fb-c92f-42f1-e416-8288c46fe0b1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ - [\n",
            "' - '\n",
            "I - I\n",
            "was - be\n",
            "born - bear\n",
            "in - in\n",
            "Madrid - Madrid\n",
            ". - .\n",
            "' - '\n",
            ", - ,\n",
            "' - '\n",
            "I - I\n",
            "was - be\n",
            "born - bear\n",
            "in - in\n",
            "Madrid - Madrid\n",
            "during - during\n",
            "1995 - 1995\n",
            ". - .\n",
            "' - '\n",
            "] - ]\n",
            "NVPN - NVPN\n",
            "2 - 2\n",
            "I - I\n",
            "bear - bear\n",
            "None - None\n",
            "in - in\n",
            "CITY - CITY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ0VTeUsDuIi"
      },
      "source": [
        "## -Stop words\n",
        "\n",
        "* Son las palabras que no aportan nada al significado de la frase.\n",
        "\n",
        "\n",
        "* spaCy dispone de más de 500 stop words en Español.\n",
        "\n",
        "\n",
        "* Veamos a continuación las Stop Words en Español."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eayd3vADuIj",
        "outputId": "fab7f021-add7-4653-966e-8a71433e5bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de stop words: 521\n",
            "Stop words: ['las', 'por', 'afirmó', 'estais', 'señaló', 'última', 'tambien', 'nuevas', 'claro', 'conocer', 'tú', 'aquel', 'próximo', 'enfrente', 'os', 'durante', 'dijo', 'sino', 'cierta', 'pueda', 'siempre', 'es', 'éstos', 'algo', 'mencionó', 'lado', 'no', 'uno', 'uso', 'sabeis', 'consigues', 'mi', 'nunca', 'estos', 'debajo', 'tu', 'bastante', 'esa', 'alli', 'había', 'unos', 'informó', 'tuvo', 'era', 'ni', 'puedo', 'doce', 'indicó', 'solamente', 'nosotros', 'algunos', 'detrás', 'estado', 'toda', 'cuatro', 'hacer', 'tiene', 'otra', 'cierto', 'fue', 'dos', 'próximos', 'hace', 'con', 'conseguir', 'dias', 'los', 'dice', 'diez', 'mas', 'final', 'usan', 'aun', 'cuanta', 'demás', 'muchos', 'habían', 'nueva', 'verdad', 'salvo', 'expresó', 'tenga', 'eran', 'sean', 'alguna', 'verdadera', 'nueve', 'mío', 'modo', 'seis', 'hacerlo', 'buen', 'sé', 'para', 'ocho', 'hasta', 'eramos', 'día', 'estamos', 'existen', 'allí', 'mal', 'teneis', 'ése', 'nuestras', 'podria', 'ahora', 'proximo', 'veces', 'aquélla', 'que', 'fuimos', 'estados', 'ahi', 'últimos', 'pudo', 'ha', 'aquéllas', 'podrán', 'así', 'tuyos', 'ti', 'cuánta', 'posible', 'creo', 'una', 'porque', 'fuera', 'propias', 'qeu', 'respecto', 'junto', 'eras', 'después', 'once', 'sin', 'haces', 'menudo', 'ningunas', 'mismo', 'haber', 'suya', 'lleva', 'estará', 'quien', 'ser', 'adelante', 'aunque', 'deben', 'éstas', 'ésos', 'saben', 'tuyo', 'parece', 'poco', 'al', 'realizó', 'ambos', 'quiza', 'además', 'despacio', 'último', 'mejor', 'estar', 'manera', 'usamos', 'través', 'vosotros', 'tengo', 'deprisa', 'ésa', 'estaba', 'contigo', 'siguiente', 'ninguna', 'todas', 'llegó', 'enseguida', 'hoy', 'diferente', 'consiguen', 'quién', 'aproximadamente', 'sigue', 'luego', 'de', 'embargo', 'yo', 'primeros', 'sobre', 'sus', 'partir', 'cuánto', 'explicó', 'dijeron', 'trata', 'tan', 'sabe', 'entre', 'dia', 'quizá', 'soy', 'tampoco', 'tienen', 'hecho', 'está', 'nuevos', 'tarde', 'atras', 'consigo', 'aquí', 'otras', 'breve', 'existe', 'mia', 'mucho', 'tuyas', 'usar', 'ningún', 'ésas', 'cuántas', 'dentro', 'podemos', 'nuestra', 'como', 'estas', 'hizo', 'asi', 'van', 'vez', 'usted', 'informo', 'menos', 'quiere', 'nada', 'estoy', 'dieron', 'cuanto', 'podrían', 'aquellos', 'mediante', 'sí', 'quiénes', 'incluso', 'mismas', 'son', 'vuestro', 'total', 'realizado', 'sabemos', 'tendrán', 'usais', 'mias', 'cómo', 'algunas', 'eso', 'grandes', 'hacen', 'fui', 'ello', 'pasado', 'u', 'buenos', 'alguno', 'últimas', 'pocas', 'podrian', 'nuevo', 'muy', 'excepto', 'podeis', 'están', 'sólo', 'fueron', 'cuál', 'cuando', 'estaban', 'hubo', 'sabes', 'vosotras', 'solos', 'bien', 'paìs', 'decir', 'manifestó', 'otro', 'sola', 'vamos', 'o', 'podriamos', 'tenemos', 'aquellas', 'gran', 'dicho', 'anterior', 'pero', 'aquella', 'segun', 'comentó', 'cuantas', 'mayor', 'cinco', 'tres', 'dan', 'debido', 'buenas', 'ante', 'mios', 'nuestro', 'dado', 'contra', 'segunda', 'ningunos', 'considera', 'fin', 'mis', 'donde', 'ya', 'aqui', 'suyo', 'nos', 'casi', 'esos', 'habla', 'será', 'aquél', 'cualquier', 'despues', 'mientras', 'el', 'tras', 'he', 'en', 'apenas', 'varios', 'supuesto', 'nuestros', 'él', 'todavía', 'misma', 'tener', 'vais', 'vuestra', 'ademas', 'aseguró', 'bueno', 'cuántos', 'días', 'pesar', 'ultimo', 'bajo', 'ésta', 'propio', 'vaya', 'sea', 'arriba', 'estuvo', 'podrias', 'medio', 'dónde', 'poner', 'podrá', 'pasada', 'hay', 'propios', 'hablan', 'acuerdo', 'consigue', 'me', 'si', 'unas', 'ir', 'demasiado', 'aún', 'cuándo', 'podriais', 'realizar', 'siete', 'quienes', 'sido', 'antes', 'han', 'buena', 'sera', 'peor', 'largo', 'todavia', 'pocos', 'esas', 'serán', 'ese', 'ellos', 'sois', 'míos', 'da', 'vuestros', 'varias', 'esta', 'quedó', 'otros', 'todos', 'a', 'detras', 'siendo', 'conseguimos', 'consideró', 'dar', 'grande', 'cada', 'diferentes', 'solo', 'cuenta', 'e', 'parte', 'hemos', 'igual', 'del', 'delante', 'tercero', 'añadió', 'esto', 'ustedes', 'se', 'la', 'cuales', 'dio', 'tuya', 'muchas', 'ella', 'hago', 'suyas', 'suyos', 'hacia', 'debe', 'estan', 'todo', 'te', 'poca', 'desde', 'ahí', 'verdadero', 'habrá', 'mismos', 'solas', 'hicieron', 'mí', 'ellas', 'mio', 'pronto', 'conmigo', 'y', 'sería', 'mucha', 'agregó', 'tenido', 'nadie', 'saber', 'ciertos', 'entonces', 'eres', 'ciertas', 'algún', 'nosotras', 'primero', 'lo', 'mías', 'repente', 'también', 'tercera', 'va', 'les', 'segundo', 'quizas', 'este', 'aquéllos', 'cuáles', 'queremos', 'quizás', 'qué', 'aquello', 'tendrá', 'somos', 'pues', 'le', 'dejó', 'puede', 'ver', 'cuantos', 'según', 'usas', 'más', 'voy', 'éste', 'podría', 'tus', 'haya', 'tanto', 'tal', 'haciendo', 'encuentra', 'llevar', 'usa', 'vuestras', 'hacemos', 'primera', 'ninguno', 'un', 'primer', 'propia', 'pueden', 'tenía', 'mía', 'haceis', 'encima', 'alrededor', 'poder', 'cual', 'temprano', 'habia', 'dicen', 'su']\n"
          ]
        }
      ],
      "source": [
        "stopwords = spacy.lang.es.stop_words.STOP_WORDS\n",
        "print('Número de stop words: ' + str(len(stopwords)))\n",
        "print('Stop words: ' + str(list(stopwords)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7OXy9voDuIk"
      },
      "source": [
        "* Los objetos de la clase ***Token*** tienen la propiedad ***is_stop*** que devuelve en Boolean indicando si el token es o no una stop word; es decir, si el ***Token*** (o palabra) esta dentro de la lista antes mostrada.\n",
        "\n",
        "\n",
        "* Veamos a continuación como obtener las stop words de una frase con spaCy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUDdz6H6DuIk",
        "outputId": "b8d0655e-3f4a-4016-94bf-f2e598a9cd6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un\n",
            "a\n",
            "por\n",
            "demasiado\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(\"Un radar multa a Mariano. Rajoy por caminar demasiado rápido\")\n",
        "for word in doc:\n",
        "    if word.is_stop:\n",
        "        print(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**##Stop words in input**"
      ],
      "metadata": {
        "id": "wIryz9btKS-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWwdUanPEZ_4",
        "outputId": "6f1cda43-b107-4c35-f593-4c6083f5f088"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import stop_words\n",
        "stopwords = stop_words.STOP_WORDS\n",
        "print('Número de stop words: ' + str(len(stopwords)))\n",
        "print('Stop words: ' + str(list(stopwords)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7Vc7qN2Kbhw",
        "outputId": "24226269-6226-4d46-cf4b-9852f7ff5b23"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de stop words: 326\n",
            "Stop words: ['yourself', 'thence', 'seemed', 'have', 'herein', 'last', 'whereby', 'first', 'give', 'without', 'upon', \"'m\", 'such', 'least', 'side', 'if', 'anyone', 'was', 'forty', 'nowhere', 'behind', 'three', 'whoever', \"'s\", 'serious', 'among', 'through', 'here', 'see', 'before', 'doing', 'no', 'why', 'to', 'never', 'hereby', 'himself', 'again', 'twenty', 'wherever', 'which', 'towards', 'when', 'thereupon', 'twelve', 'below', 'off', 'who', 'him', 'but', '’s', 'your', 'top', 'eight', 'down', 'whereupon', '‘d', 'therefore', '’ve', 'whose', 'already', 'this', 'about', 'above', 'she', \"'ve\", 'every', 'do', 'in', 'what', 'into', 'sixty', 'enough', 'herself', 'via', 'toward', 'whatever', 'seeming', 'will', 'front', 'per', 'anything', \"n't\", 'indeed', 'thru', 'once', 'hers', 'beforehand', 'elsewhere', 'ours', 'six', 'these', 'often', 'thus', 'been', 'that', 'well', 'few', 'becoming', 'always', 'for', 'further', 'mostly', 'namely', 'their', 'during', 'something', 'all', '’m', 'you', 'us', 'wherein', 'ca', 'whereafter', 'around', 'beside', 'our', 'under', 'has', 'both', 'seem', 'alone', 'itself', 'so', 'very', 'myself', 'show', 'eleven', 'five', 'ten', 'any', 'hereafter', 'otherwise', '‘ll', '‘re', 'since', 'using', 'within', 'not', 'i', 'as', 'too', 'put', 'while', 'each', 'whence', 'up', 'from', 'are', 'along', 'at', 'several', 'most', 'get', 'almost', 'only', 'own', 'say', 'everyone', \"'re\", 'can', 'then', 'four', 'make', 'seems', 'amount', 'someone', 'ourselves', 'bottom', '‘ve', 'except', 'really', 'full', 'whither', 'may', 'afterwards', 'on', 'part', 'amongst', 'none', 'beyond', 'of', 'made', 'more', 'fifty', 'much', 'take', 'due', 'noone', 'be', 'cannot', 'n’t', 'them', 'else', 'used', 'anyway', 'others', 'done', 'rather', 'we', 'third', 'everything', '‘s', 'he', 'please', 'unless', 'besides', 'because', 'yet', 'either', 'therein', 'had', 'next', 'latterly', 'by', 'anyhow', 'go', 'many', '’re', 'quite', 'however', 'somehow', 'it', 'his', 'keep', 'various', 'whenever', 'onto', 'they', 'other', 'me', 'nine', 'become', 'whereas', 'its', 'would', 'another', 'one', 'thereafter', 'becomes', 'yours', 'were', 'yourselves', 'hundred', 'her', 'sometimes', 'anywhere', \"'d\", 'though', 'whom', 'empty', '’ll', 'those', 'a', 'same', 'nevertheless', 'thereby', '’d', 'some', 'with', 'the', 'did', 'across', 'mine', 'being', 'whole', 'or', 'hereupon', 'former', 'fifteen', 'call', 'less', 'move', 'an', 'themselves', 're', 'than', 'hence', 'back', 'how', 'still', 'formerly', 'after', 'latter', 'nobody', 'there', 'does', 'whether', 'moreover', 'two', 'is', 'until', 'nothing', 'am', 'might', 'and', 'nor', 'somewhere', 'even', 'against', 'also', 'although', 'should', 'meanwhile', 'ever', 'perhaps', 'sometime', 'name', 'over', 'now', \"'ll\", 'just', 'could', 'became', 'together', 'must', 'where', 'my', '‘m', 'between', 'out', 'regarding', 'throughout', 'n‘t', 'everywhere', 'neither']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = nlp(\"Jane bought me these books.Jane bought a book for me.She dropped a line to him. Thank you.She sleeps.I sleep a lot.I was born in Madrid.the cat was chased by the dog.I was born in Madrid during 1995.Out of all this , something good will come.Susan left after the rehearsal. She did it well.She sleeps during the morning, but she sleeps.\")\n",
        "for word in input:\n",
        "    if word.is_stop:\n",
        "        print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9aYQOiWKqHp",
        "outputId": "ef3f48ab-6284-4add-9803-127dcbd6c0b7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "me\n",
            "these\n",
            "a\n",
            "for\n",
            "me\n",
            "She\n",
            "a\n",
            "to\n",
            "him\n",
            "you\n",
            "She\n",
            "I\n",
            "a\n",
            "I\n",
            "was\n",
            "in\n",
            "was\n",
            "by\n",
            "the\n",
            "I\n",
            "was\n",
            "in\n",
            "during\n",
            "of\n",
            "all\n",
            "this\n",
            "something\n",
            "will\n",
            "after\n",
            "the\n",
            "She\n",
            "did\n",
            "it\n",
            "well\n",
            "She\n",
            "during\n",
            "the\n",
            "but\n",
            "she\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**##Stop words in output**"
      ],
      "metadata": {
        "id": "0Aql6KYiK4jE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.read_json(\"https://raw.githubusercontent.com/Viny2030/datasets/refs/heads/main/output.json\")"
      ],
      "metadata": {
        "id": "MYwxCg7UK9kk"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = nlp(output.iloc[:,0].astype(str).str.cat(sep=' '))"
      ],
      "metadata": {
        "id": "CjSfSKGILB1t"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy pandas\n",
        "import spacy\n",
        "import pandas as pd\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnXl6SmEGT45",
        "outputId": "3e9b250c-5269-4eb5-e884-bf691cd023a3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load the JSON data into a Pandas DataFrame\n",
        "output = pd.read_json(\"https://raw.githubusercontent.com/Viny2030/datasets/refs/heads/main/output.json\")\n",
        "\n",
        "# Process each row of the DataFrame individually\n",
        "for index, row in output.iterrows():\n",
        "    # Convert the current row to a string\n",
        "    text = str(row.iloc[0])\n",
        "\n",
        "    # Process the text with spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Print stop words in the current row\n",
        "    for word in doc:\n",
        "        if word.is_stop:\n",
        "            print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP55RDtCGZhx",
        "outputId": "ce241938-72f7-40e5-c6a4-d95b3611556e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n",
            "was\n",
            "in\n",
            "I\n",
            "was\n",
            "in\n",
            "during\n",
            "I\n",
            "None\n",
            "in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "disRZZqvDuIl"
      },
      "source": [
        "## -Part of Speech (PoS)\n",
        "\n",
        "* En ***spaCy*** el PoS lo divide en 3 tipos de tags que son:\n",
        "    1. **pos**: etiqueta simple de alto nivel (verbo, nombre, adjetivo, etc).\n",
        "    2. **tag**: etiqueta con más nivel de detalle que el pos.\n",
        "    3. **dep**: dependencia sintáctica para ver la relación entre tokens.\n",
        "\n",
        "\n",
        "* Estos 3 tipos son propiedades de la clase ***Token***:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "RvbnyK22DuIl",
        "outputId": "a9e05ad2-a866-4970-cb9f-f2730e3b947a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Text    PoS    TAG     DEP\n",
              "0          Un    DET    DET     det\n",
              "1       radar   NOUN   NOUN    ROOT\n",
              "2       multa   NOUN   NOUN    amod\n",
              "3           a    ADP    ADP    case\n",
              "4     Mariano  PROPN  PROPN    nmod\n",
              "5       Rajoy  PROPN  PROPN    flat\n",
              "6         con    ADP    ADP    case\n",
              "7         300    NUM    NUM  nummod\n",
              "8           €   NOUN   NOUN    nmod\n",
              "9         por    ADP    ADP    mark\n",
              "10    caminar   VERB   VERB     acl\n",
              "11  demasiado    ADV    ADV  advmod\n",
              "12     rápido    ADJ    ADJ  advmod"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f396d4a-eb1c-40cf-a624-ff053714fb19\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>PoS</th>\n",
              "      <th>TAG</th>\n",
              "      <th>DEP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Un</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>radar</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>ROOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>multa</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>amod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mariano</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>nmod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Rajoy</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>flat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>con</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>300</td>\n",
              "      <td>NUM</td>\n",
              "      <td>NUM</td>\n",
              "      <td>nummod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>€</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>nmod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>por</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>mark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>caminar</td>\n",
              "      <td>VERB</td>\n",
              "      <td>VERB</td>\n",
              "      <td>acl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>demasiado</td>\n",
              "      <td>ADV</td>\n",
              "      <td>ADV</td>\n",
              "      <td>advmod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>rápido</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>advmod</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f396d4a-eb1c-40cf-a624-ff053714fb19')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2f396d4a-eb1c-40cf-a624-ff053714fb19 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2f396d4a-eb1c-40cf-a624-ff053714fb19');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-568c9084-28df-4321-8238-6df0296fa764\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-568c9084-28df-4321-8238-6df0296fa764')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-568c9084-28df-4321-8238-6df0296fa764 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 13,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"demasiado\",\n          \"por\",\n          \"Un\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PoS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"NOUN\",\n          \"VERB\",\n          \"DET\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TAG\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"NOUN\",\n          \"VERB\",\n          \"DET\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DEP\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"acl\",\n          \"ROOT\",\n          \"flat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "doc = nlp(\"Un radar multa a Mariano Rajoy con 300€ por caminar demasiado rápido\")\n",
        "pos = [[tk.text, tk.pos_, tk.tag_, tk.dep_] for tk in doc]\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(pos, columns=[\"Text\", \"PoS\", \"TAG\", \"DEP\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **-Part of Speech (PoS)_input**\n",
        "En spaCy el PoS lo divide en 3 tipos de tags que son:\n",
        "pos: etiqueta simple de alto nivel (verbo, nombre, adjetivo, etc).\n",
        "tag: etiqueta con más nivel de detalle que el pos.\n",
        "dep: dependencia sintáctica para ver la relación entre tokens.\n",
        "Estos 3 tipos son propiedades de la clase Token:"
      ],
      "metadata": {
        "id": "ufqU6vebLVK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wKPCUjWCGxys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = nlp(\"Jane bought me these books.Jane bought a book for me.She dropped a line to him. Thank you.She sleeps.I sleep a lot.I was born in Madrid.the cat was chased by the dog.I was born in Madrid during 1995.Out of all this , something good will come.Susan left after the rehearsal. She did it well.She sleeps during the morning, but she sleeps.\")"
      ],
      "metadata": {
        "id": "eh2J72FoG6pB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Your input text\n",
        "input_text = \"Jane bought me these books.Jane bought a book for me.She dropped a line to him. Thank you.She sleeps.I sleep a lot.I was born in Madrid.the cat was chased by the dog.I was born in Madrid during 1995.Out of all this , something good will come.Susan left after the rehearsal. She did it well.She sleeps during the morning, but she sleeps.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(input_text)\n",
        "\n",
        "# Initialize an empty list to store the data\n",
        "data = []\n",
        "\n",
        "# Iterate over sentences in the Doc object\n",
        "for sent in doc.sents:\n",
        "    # Iterate over tokens in each sentence\n",
        "    for tk in sent:\n",
        "        # Append token information to the data list\n",
        "        data.append([tk.text, tk.pos_, tk.tag_, tk.dep_])\n",
        "\n",
        "# Create a Pandas DataFrame from the collected data\n",
        "df = pd.DataFrame(data, columns=[\"Text\", \"PoS\", \"TAG\", \"DEP\"])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX8Yvl7NHJuG",
        "outputId": "683a0a7b-5775-41c7-fc05-0ffa4d9889eb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Text    PoS  TAG     DEP\n",
            "0     Jane  PROPN  NNP   nsubj\n",
            "1   bought   VERB  VBD    ROOT\n",
            "2       me   PRON  PRP  dative\n",
            "3    these    DET   DT     det\n",
            "4    books   NOUN  NNS    dobj\n",
            "..     ...    ...  ...     ...\n",
            "75       ,  PUNCT    ,   punct\n",
            "76     but  CCONJ   CC      cc\n",
            "77     she   PRON  PRP   nsubj\n",
            "78  sleeps   VERB  VBZ    conj\n",
            "79       .  PUNCT    .   punct\n",
            "\n",
            "[80 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **-Part of Speech (PoS)_output**\n",
        "En spaCy el PoS lo divide en 3 tipos de tags que son:\n",
        "pos: etiqueta simple de alto nivel (verbo, nombre, adjetivo, etc).\n",
        "tag: etiqueta con más nivel de detalle que el pos.\n",
        "dep: dependencia sintáctica para ver la relación entre tokens.\n",
        "Estos 3 tipos son propiedades de la clase Token:"
      ],
      "metadata": {
        "id": "k_TfRZACGyIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load the JSON data into a Pandas DataFrame\n",
        "df = pd.read_json(\"https://raw.githubusercontent.com/Viny2030/datasets/refs/heads/main/output.json\")\n",
        "\n",
        "# Process each row of the DataFrame individually\n",
        "all_pos = []\n",
        "for index, row in df.iterrows(): # Iterate over the rows of the dataframe\n",
        "    # Convert the current row to a string\n",
        "    text = str(row.iloc[0])\n",
        "\n",
        "    # Process the text with spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Extract POS information for each token in the document\n",
        "    pos = [[tk.text, tk.pos_, tk.tag_, tk.dep_] for tk in doc]\n",
        "\n",
        "    # Add the POS information to the main list\n",
        "    all_pos.extend(pos)\n",
        "\n",
        "# Create a Pandas DataFrame from the collected data\n",
        "pos_df = pd.DataFrame(all_pos, columns=[\"Text\", \"PoS\", \"TAG\", \"DEP\"])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(pos_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E21UiguxHkBO",
        "outputId": "3ecb6c29-f258-42a9-8350-2e9a61abcaeb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Text    PoS    TAG        DEP\n",
            "0        [      X     XX        dep\n",
            "1        '  PUNCT     ``      punct\n",
            "2        I   PRON    PRP  nsubjpass\n",
            "3      was    AUX    VBD    auxpass\n",
            "4     born   VERB    VBN      ccomp\n",
            "5       in    ADP     IN       prep\n",
            "6   Madrid  PROPN    NNP       pobj\n",
            "7        .  PUNCT      .      punct\n",
            "8        '  PUNCT     ''      punct\n",
            "9        ,  PUNCT      ,      punct\n",
            "10       '  PUNCT     ``      punct\n",
            "11       I   PRON    PRP  nsubjpass\n",
            "12     was    AUX    VBD    auxpass\n",
            "13    born   VERB    VBN       ROOT\n",
            "14      in    ADP     IN       prep\n",
            "15  Madrid  PROPN    NNP       pobj\n",
            "16  during    ADP     IN       prep\n",
            "17    1995    NUM     CD       pobj\n",
            "18       .  PUNCT      .      punct\n",
            "19       '  PUNCT     ''      punct\n",
            "20       ]  PUNCT  -RRB-      punct\n",
            "21    NVPN  PROPN    NNP       ROOT\n",
            "22       2    NUM     CD       ROOT\n",
            "23       I   PRON    PRP       ROOT\n",
            "24    bear   VERB     VB       ROOT\n",
            "25    None   NOUN     NN       ROOT\n",
            "26      in    ADP     IN       ROOT\n",
            "27    CITY  PROPN    NNP       ROOT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LPOpF2ZHQQj",
        "outputId": "fefcac09-06e7-4c25-c64d-a633dedeb15f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I was born in Madrid.', 'I was born in Madrid during 1995.'] NVPN 2 I bear None in CITY"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPFYmC3IDuIm"
      },
      "source": [
        "## -Named Entity Recognition (NER)\n",
        "\n",
        "* Named Entity Recognition (Reconocimiento de Entidades Nombradas) es una tarea de extracción de información que busca localizar y clasificar en categorías predefinidas, como personas, organizaciones, lugares, expresiones de tiempo y cantidades, las entidades nombradas encontradas en un texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Z9yLFrweDuIn",
        "outputId": "83b10afa-3347-424c-d067-d0e17c85ec96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leo Messi - GPE - Countries, cities, states\n",
            "FC - ORG - Companies, agencies, institutions, etc.\n",
            "34 - CARDINAL - Numerals that do not fall under another type\n",
            "La Liga 2017-18 - FAC - Buildings, airports, highways, bridges, etc.\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(\"Leo Messi jugador del FC Barcelona marco 34 en La Liga 2017-18\")\n",
        "for entity in doc.ents:\n",
        "    print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SVxjPPOzHt36"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkIGHFzQHuIi"
      },
      "source": [
        "## -Named Entity Recognition (NER)-input\n",
        "\n",
        "* Named Entity Recognition (Reconocimiento de Entidades Nombradas) es una tarea de extracción de información que busca localizar y clasificar en categorías predefinidas, como personas, organizaciones, lugares, expresiones de tiempo y cantidades, las entidades nombradas encontradas en un texto."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = nlp(\"Jane bought me these books.Jane bought a book for me.She dropped a line to him. Thank you.She sleeps.I sleep a lot.I was born in Madrid.the cat was chased by the dog.I was born in Madrid during 1995.Out of all this , something good will come.Susan left after the rehearsal. She did it well.She sleeps during the morning, but she sleeps.\")"
      ],
      "metadata": {
        "id": "ZSSx6fB5H2_T"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for entity in input.ents:\n",
        "    print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCtJbEO7H5v-",
        "outputId": "2139f419-b76c-48f9-e742-fb77f298eade"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jane - PERSON - People, including fictional\n",
            "Jane - PERSON - People, including fictional\n",
            "Madrid - GPE - Countries, cities, states\n",
            "1995.Out - CARDINAL - Numerals that do not fall under another type\n",
            "Susan - PERSON - People, including fictional\n",
            "the morning - TIME - Times smaller than a day\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mI0qcwTIH-FF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE-XaiphH-VO"
      },
      "source": [
        "## -Named Entity Recognition (NER)-output\n",
        "\n",
        "* Named Entity Recognition (Reconocimiento de Entidades Nombradas) es una tarea de extracción de información que busca localizar y clasificar en categorías predefinidas, como personas, organizaciones, lugares, expresiones de tiempo y cantidades, las entidades nombradas encontradas en un texto."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the JSON data into a Pandas DataFrame\n",
        "df = pd.read_json(\"https://raw.githubusercontent.com/Viny2030/datasets/refs/heads/main/output.json\")\n",
        "\n",
        "# Process each row of the DataFrame individually\n",
        "all_pos = []\n",
        "for index, row in df.iterrows(): # Iterate over the rows of the dataframe\n",
        "    # Convert the current row to a string\n",
        "    text = str(row.iloc[0])\n",
        "\n",
        "    # Process the text with spaCy\n",
        "    doc = nlp(text)\n",
        "for entity in doc.ents:\n",
        "    print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))"
      ],
      "metadata": {
        "id": "OZGpGvUOIF4E"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for entity in doc.ents:\n",
        "    print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))"
      ],
      "metadata": {
        "id": "w7eyj1qNITxD"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n4mCTMlDuIo"
      },
      "source": [
        "\n",
        "<hr>\n",
        "\n",
        "\n",
        "# -Resumen\n",
        "\n",
        "* Una vez creado el documento a partir del texto plano, tenemos ese texto tokenizado.\n",
        "\n",
        "\n",
        "* Los objetos de la clase ***Token*** tienen una serie de propiedades que permiten obtener mucha información relativa a los tokens (o palabras).\n",
        "\n",
        "\n",
        "* Haciendo un resumen de lo visto anteriormente podemos obtener la siguiente información de las palabras de un texto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "scrolled": false,
        "id": "UlKlB_A-DuIo",
        "outputId": "f03e8e9c-27f8-4ca5-b2bb-d0abbe3ba449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Text       Lema    PoS    TAG     DEP  Shape  Alpha  is Stop word\n",
              "0          Un        uno    DET    DET     det     Xx   True          True\n",
              "1       radar      radar   NOUN   NOUN    ROOT   xxxx   True         False\n",
              "2       multa      multa   NOUN   NOUN    amod   xxxx   True         False\n",
              "3           a          a    ADP    ADP    case      x   True          True\n",
              "4     Mariano    Mariano  PROPN  PROPN    nmod  Xxxxx   True         False\n",
              "5       Rajoy      Rajoy  PROPN  PROPN    flat  Xxxxx   True         False\n",
              "6         con        con    ADP    ADP    case    xxx   True          True\n",
              "7         300        300    NUM    NUM  nummod    ddd  False         False\n",
              "8           €          €   NOUN   NOUN    nmod      €  False         False\n",
              "9         por        por    ADP    ADP    mark    xxx   True          True\n",
              "10    caminar    caminar   VERB   VERB     acl   xxxx   True         False\n",
              "11  demasiado  demasiado    ADV    ADV  advmod   xxxx   True          True\n",
              "12     rápido     rápido    ADJ    ADJ  advmod   xxxx   True         False"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4120856-da73-4c48-8479-5285419caf6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Lema</th>\n",
              "      <th>PoS</th>\n",
              "      <th>TAG</th>\n",
              "      <th>DEP</th>\n",
              "      <th>Shape</th>\n",
              "      <th>Alpha</th>\n",
              "      <th>is Stop word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Un</td>\n",
              "      <td>uno</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "      <td>Xx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>radar</td>\n",
              "      <td>radar</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>multa</td>\n",
              "      <td>multa</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>amod</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "      <td>x</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mariano</td>\n",
              "      <td>Mariano</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>nmod</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Rajoy</td>\n",
              "      <td>Rajoy</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>flat</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>con</td>\n",
              "      <td>con</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "      <td>xxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>300</td>\n",
              "      <td>300</td>\n",
              "      <td>NUM</td>\n",
              "      <td>NUM</td>\n",
              "      <td>nummod</td>\n",
              "      <td>ddd</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>€</td>\n",
              "      <td>€</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>nmod</td>\n",
              "      <td>€</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>por</td>\n",
              "      <td>por</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>mark</td>\n",
              "      <td>xxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>caminar</td>\n",
              "      <td>caminar</td>\n",
              "      <td>VERB</td>\n",
              "      <td>VERB</td>\n",
              "      <td>acl</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>demasiado</td>\n",
              "      <td>demasiado</td>\n",
              "      <td>ADV</td>\n",
              "      <td>ADV</td>\n",
              "      <td>advmod</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>rápido</td>\n",
              "      <td>rápido</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>advmod</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4120856-da73-4c48-8479-5285419caf6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a4120856-da73-4c48-8479-5285419caf6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a4120856-da73-4c48-8479-5285419caf6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-af24c7f5-bc99-498b-8441-d01e0ef5cac3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af24c7f5-bc99-498b-8441-d01e0ef5cac3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-af24c7f5-bc99-498b-8441-d01e0ef5cac3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 13,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"demasiado\",\n          \"por\",\n          \"Un\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lema\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"demasiado\",\n          \"por\",\n          \"uno\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PoS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"NOUN\",\n          \"VERB\",\n          \"DET\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TAG\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"NOUN\",\n          \"VERB\",\n          \"DET\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DEP\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"acl\",\n          \"ROOT\",\n          \"flat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shape\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Xx\",\n          \"xxxx\",\n          \"ddd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alpha\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is Stop word\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "doc = nlp(\"Un radar multa a Mariano Rajoy con 300€ por caminar demasiado rápido\")\n",
        "\n",
        "result = [[tk.text, tk.lemma_, tk.pos_, tk.tag_, tk.dep_, tk.shape_, tk.is_alpha, tk.is_stop] for tk in doc]\n",
        "pd.DataFrame(result, columns=[\"Text\", \"Lema\", \"PoS\", \"TAG\", \"DEP\", \"Shape\", \"Alpha\", \"is Stop word\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_RfoiboDuIp"
      },
      "source": [
        "#### Para más información visitar el siguiente enlace: https://spacy.io/usage/spacy-101#annotations"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}