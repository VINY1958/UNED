{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Viny2030/UNED/blob/main/10_Extract_text_from_documents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pjmz-RORV8E"
      },
      "source": [
        "# Extract text from documents\n",
        "\n",
        "Up to this point, all the examples have been working with sections of text, which have already been split through some other means. What happens if we're working with documents? First we need to get the text out of these documents, then figure out how to index to best support vector search.\n",
        "\n",
        "This notebook shows how documents can have text extracted and split to support vector search and retrieval augmented generation (RAG)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extraer texto de documentos**\n",
        "Hasta este punto, todos los ejemplos han estado trabajando con secciones de texto, que ya se han dividido a través de otros medios. ¿Qué sucede si estamos trabajando con documentos? Primero necesitamos sacar el texto de estos documentos, luego descubrir cómo indexar a la mejor búsqueda de vectores de soporte.\n",
        "\n",
        "Este cuaderno muestra cómo los documentos pueden extraer y dividir el texto para admitir la búsqueda y la recuperación de la generación aumentada (RAG)."
      ],
      "metadata": {
        "id": "M2UDjtDMzdu5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk31rbYjSTYm"
      },
      "source": [
        "# Install dependencies\n",
        "\n",
        "Install `txtai` and all dependencies. Since this notebook is using optional pipelines, we need to install the pipeline extras package."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instalar dependencias**\n",
        "Instale TXTAI y todas las dependencias. Dado que este cuaderno está utilizando tuberías opcionales, necesitamos instalar el paquete de extras de tuberías."
      ],
      "metadata": {
        "id": "mnM12fzL1aNS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMQuuun2R06J"
      },
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/neuml/txtai#egg=txtai[pipeline]\n",
        "\n",
        "# Get test data\n",
        "!wget -N https://github.com/neuml/txtai/releases/download/v6.2.0/tests.tar.gz\n",
        "!tar -xvzf tests.tar.gz\n",
        "\n",
        "# Install NLTK\n",
        "import nltk\n",
        "nltk.download(['punkt', 'punkt_tab'])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNPJ95cdTKSS"
      },
      "source": [
        "# Create a Textractor instance\n",
        "\n",
        "The Textractor instance is the main entrypoint for extracting text. This method is backed by Apache Tika, a robust text extraction library written in Java. [Apache Tika](https://tika.apache.org/0.9/formats.html) has support for a large number of file formats: PDF, Word, Excel, HTML and others. The [Python Tika package](https://github.com/chrismattmann/tika-python) automatically installs Tika and starts a local REST API instance used to read extracted data.\n",
        "\n",
        "*Note: This requires Java to be installed locally.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear una instancia de Textractor\n",
        "La instancia de Textractor es el punto de entrada principal para extraer texto. Este método está respaldado por Apache Tika, una sólida biblioteca de extracción de texto escrita en Java. Apache Tika tiene soporte para una gran cantidad de formatos de archivo: PDF, Word, Excel, HTML y otros. El paquete Python Tika instala automáticamente Tika e inicia una instancia de API REST local utilizada para leer datos extraídos.\n",
        "\n",
        "Nota: Esto requiere que Java se instale localmente."
      ],
      "metadata": {
        "id": "MyPaaxlh18aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install java -y\n",
        "!java --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpmxyJPK1-gB",
        "outputId": "8575038a-476e-41d7-d678-42e68bbc59f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -y\n",
            "openjdk 11.0.25 2024-10-15\n",
            "OpenJDK Runtime Environment (build 11.0.25+9-post-Ubuntu-1ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.25+9-post-Ubuntu-1ubuntu122.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTDwXOUeTH2-"
      },
      "source": [
        "%%capture\n",
        "\n",
        "from txtai.pipeline import Textractor\n",
        "\n",
        "# Create textractor model\n",
        "textractor = Textractor()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vGR_piwZZO6"
      },
      "source": [
        "# Extract text\n",
        "\n",
        "The example below shows how to extract text from a file."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraer texto\n",
        "El siguiente ejemplo muestra cómo extraer texto de un archivo."
      ],
      "metadata": {
        "id": "ycfyWZxY4rtG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "-K2YJJzsVtfq",
        "outputId": "f5ae4773-6d51-451a-c17b-4099aa0fbb6d"
      },
      "source": [
        "textractor(\"txtai/article.pdf\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tika.tika:Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/2.6.0/tika-server-standard-2.6.0.jar to /tmp/tika-server.jar.\n",
            "INFO:tika.tika:Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/2.6.0/tika-server-standard-2.6.0.jar.md5 to /tmp/tika-server.jar.md5.\n",
            "WARNING:tika.tika:Failed to see startup log message; retrying...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Introducing txtai, an AI-powered search engine \\nbuilt on Transformers\\n\\nAdd Natural Language Understanding to any application\\n\\nSearch is the base of many applications. Once data starts to pile up, users want to be able to find it. It’s \\nthe foundation of the internet and an ever-growing challenge that is never solved or done.\\n\\nThe field of Natural Language Processing (NLP) is rapidly evolving with a number of new \\ndevelopments. Large-scale general language models are an exciting new capability allowing us to add \\namazing functionality quickly with limited compute and people. Innovation continues with new models\\nand advancements coming in at what seems a weekly basis.\\n\\nThis article introduces txtai, an AI-powered search engine that enables Natural Language \\nUnderstanding (NLU) based search in any application.\\n\\nIntroducing txtai\\ntxtai builds an AI-powered index over sections of text. txtai supports building text indices to perform \\nsimilarity searches and create extractive question-answering based systems. txtai also has functionality \\nfor zero-shot classification. txtai is open source and available on GitHub.\\n\\ntxtai and/or the concepts behind it has already been used to power the Natural Language Processing \\n(NLP) applications listed below:\\n\\n• paperai — AI-powered literature discovery and review engine for medical/scientific papers\\n• tldrstory — AI-powered understanding of headlines and story text\\n• neuspo — Fact-driven, real-time sports event and news site\\n• codequestion — Ask coding questions directly from the terminal\\n\\nBuild an Embeddings index\\nFor small lists of texts, the method above works. But for larger repositories of documents, it doesn’t \\nmake sense to tokenize and convert all embeddings for each query. txtai supports building pre-\\ncomputed indices which significantly improves performance.\\n\\nBuilding on the previous example, the following example runs an index method to build and store the \\ntext embeddings. In this case, only the query is converted to an embeddings vector each search.\\n\\n[https://github.com/neuml/codequestion](https://github.com/neuml/codequestion) \\n[https://neuspo.com/](https://neuspo.com/) \\n[https://github.com/neuml/tldrstory](https://github.com/neuml/tldrstory) \\n[https://github.com/neuml/paperai](https://github.com/neuml/paperai) \\n- Introducing txtai, an AI-powered search engine built on Transformers\\n- Add Natural Language Understanding to any application\\n- Introducing txtai\\n- Build an Embeddings index'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2jndgE-JyWX"
      },
      "source": [
        "Note that the text from the article was extracted into a single string. Depending on the articles, this may be acceptable. For long articles, often you'll want to split the content into logical sections to build better downstream vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tenga en cuenta que el texto del artículo se extrajo en una sola cadena. Dependiendo de los artículos, esto puede ser aceptable. Para artículos largos, a menudo querrá dividir el contenido en secciones lógicas para construir mejores vectores aguas abajo."
      ],
      "metadata": {
        "id": "8BSGtETa4w6N"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w2bhBCPOUdu"
      },
      "source": [
        "# Extract sentences\n",
        "\n",
        "Sentence extraction uses a model that specializes in sentence detection. This call returns a list of sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraer oraciones\n",
        "La extracción de oraciones utiliza un modelo que se especializa en la detección de oraciones. Esta llamada devuelve una lista de oraciones."
      ],
      "metadata": {
        "id": "US4qnibF46mZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKZVK5vuOTqB",
        "outputId": "5aff0bd3-034d-4a90-b17b-074229ec3cf6"
      },
      "source": [
        "textractor = Textractor(sentences=True)\n",
        "textractor(\"txtai/article.pdf\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Introducing txtai, an AI-powered search engine \\nbuilt on Transformers\\n\\nAdd Natural Language Understanding to any application\\n\\nSearch is the base of many applications.',\n",
              " 'Once data starts to pile up, users want to be able to find it.',\n",
              " 'It’s \\nthe foundation of the internet and an ever-growing challenge that is never solved or done.',\n",
              " 'The field of Natural Language Processing (NLP) is rapidly evolving with a number of new \\ndevelopments.',\n",
              " 'Large-scale general language models are an exciting new capability allowing us to add \\namazing functionality quickly with limited compute and people.',\n",
              " 'Innovation continues with new models\\nand advancements coming in at what seems a weekly basis.',\n",
              " 'This article introduces txtai, an AI-powered search engine that enables Natural Language \\nUnderstanding (NLU) based search in any application.',\n",
              " 'Introducing txtai\\ntxtai builds an AI-powered index over sections of text.',\n",
              " 'txtai supports building text indices to perform \\nsimilarity searches and create extractive question-answering based systems.',\n",
              " 'txtai also has functionality \\nfor zero-shot classification.',\n",
              " 'txtai is open source and available on GitHub.',\n",
              " 'txtai and/or the concepts behind it has already been used to power the Natural Language Processing \\n(NLP) applications listed below:\\n\\n• paperai — AI-powered literature discovery and review engine for medical/scientific papers\\n• tldrstory — AI-powered understanding of headlines and story text\\n• neuspo — Fact-driven, real-time sports event and news site\\n• codequestion — Ask coding questions directly from the terminal\\n\\nBuild an Embeddings index\\nFor small lists of texts, the method above works.',\n",
              " 'But for larger repositories of documents, it doesn’t \\nmake sense to tokenize and convert all embeddings for each query.',\n",
              " 'txtai supports building pre-\\ncomputed indices which significantly improves performance.',\n",
              " 'Building on the previous example, the following example runs an index method to build and store the \\ntext embeddings.',\n",
              " 'In this case, only the query is converted to an embeddings vector each search.',\n",
              " '[https://github.com/neuml/codequestion](https://github.com/neuml/codequestion) \\n[https://neuspo.com/](https://neuspo.com/) \\n[https://github.com/neuml/tldrstory](https://github.com/neuml/tldrstory) \\n[https://github.com/neuml/paperai](https://github.com/neuml/paperai) \\n- Introducing txtai, an AI-powered search engine built on Transformers\\n- Add Natural Language Understanding to any application\\n- Introducing txtai\\n- Build an Embeddings index']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdVCCc9UOv5S"
      },
      "source": [
        "Now the document is split up at the sentence level. These sentences can be feed to a workflow that adds each sentence to an embeddings index. Depending on the task, this may work well. Alternatively, it may be even better to split at the paragraph level."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora el documento se divide en el nivel de oración. Estas oraciones se pueden alimentar a un flujo de trabajo que agrega cada oración a un índice de incrustaciones. Dependiendo de la tarea, esto puede funcionar bien. Alternativamente, puede ser aún mejor dividirse a nivel de párrafo."
      ],
      "metadata": {
        "id": "bTJwLAkB5Ky0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1H8XYkaSoP4"
      },
      "source": [
        "# Extract paragraphs\n",
        "\n",
        "Paragraph detection looks for consecutive newlines. This call returns a list of paragraphs."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraer párrafos\n",
        "La detección de párrafos busca nuevas líneas consecutivas. Esta llamada devuelve una lista de párrafos."
      ],
      "metadata": {
        "id": "uL2DMzJh5QTy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VUito4ISoAe",
        "outputId": "fa5d7bce-1187-46d0-d60d-bf40fd77a4d1"
      },
      "source": [
        "textractor = Textractor(paragraphs=True)\n",
        "for paragraph in textractor(\"txtai/article.pdf\"):\n",
        "  print(paragraph, \"\\n----\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Introducing txtai, an AI-powered search engine \n",
            "built on Transformers \n",
            "----\n",
            "Add Natural Language Understanding to any application \n",
            "----\n",
            "Search is the base of many applications. Once data starts to pile up, users want to be able to find it. It’s \n",
            "the foundation of the internet and an ever-growing challenge that is never solved or done. \n",
            "----\n",
            "The field of Natural Language Processing (NLP) is rapidly evolving with a number of new \n",
            "developments. Large-scale general language models are an exciting new capability allowing us to add \n",
            "amazing functionality quickly with limited compute and people. Innovation continues with new models\n",
            "and advancements coming in at what seems a weekly basis. \n",
            "----\n",
            "This article introduces txtai, an AI-powered search engine that enables Natural Language \n",
            "Understanding (NLU) based search in any application. \n",
            "----\n",
            "Introducing txtai\n",
            "txtai builds an AI-powered index over sections of text. txtai supports building text indices to perform \n",
            "similarity searches and create extractive question-answering based systems. txtai also has functionality \n",
            "for zero-shot classification. txtai is open source and available on GitHub. \n",
            "----\n",
            "txtai and/or the concepts behind it has already been used to power the Natural Language Processing \n",
            "(NLP) applications listed below: \n",
            "----\n",
            "• paperai — AI-powered literature discovery and review engine for medical/scientific papers\n",
            "• tldrstory — AI-powered understanding of headlines and story text\n",
            "• neuspo — Fact-driven, real-time sports event and news site\n",
            "• codequestion — Ask coding questions directly from the terminal \n",
            "----\n",
            "Build an Embeddings index\n",
            "For small lists of texts, the method above works. But for larger repositories of documents, it doesn’t \n",
            "make sense to tokenize and convert all embeddings for each query. txtai supports building pre-\n",
            "computed indices which significantly improves performance. \n",
            "----\n",
            "Building on the previous example, the following example runs an index method to build and store the \n",
            "text embeddings. In this case, only the query is converted to an embeddings vector each search. \n",
            "----\n",
            "[https://github.com/neuml/codequestion](https://github.com/neuml/codequestion) \n",
            "[https://neuspo.com/](https://neuspo.com/) \n",
            "[https://github.com/neuml/tldrstory](https://github.com/neuml/tldrstory) \n",
            "[https://github.com/neuml/paperai](https://github.com/neuml/paperai) \n",
            "- Introducing txtai, an AI-powered search engine built on Transformers\n",
            "- Add Natural Language Understanding to any application\n",
            "- Introducing txtai\n",
            "- Build an Embeddings index \n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract sections\n",
        "\n",
        "Section extraction is format dependent. If page breaks are available, each section is a page. Otherwise, this call returns logical sections such by headings."
      ],
      "metadata": {
        "id": "Ae6dRQ2LvN-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Secciones de extracción**\n",
        "La extracción de la sección depende del formato. Si hay saltos de página disponibles, cada sección es una página. De lo contrario, esta llamada devuelve secciones lógicas tales por encabezados."
      ],
      "metadata": {
        "id": "8rz4VDRf5V2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textractor = Textractor(sections=True)\n",
        "print(\"\\n[PAGE BREAK]\\n\".join(section for section in textractor(\"txtai/article.pdf\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ6ev2UMwqnh",
        "outputId": "8a4efe15-e6b2-43ac-902a-52fed3c89944"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Introducing txtai, an AI-powered search engine \n",
            "built on Transformers\n",
            "\n",
            "Add Natural Language Understanding to any application\n",
            "\n",
            "Search is the base of many applications. Once data starts to pile up, users want to be able to find it. It’s \n",
            "the foundation of the internet and an ever-growing challenge that is never solved or done.\n",
            "\n",
            "The field of Natural Language Processing (NLP) is rapidly evolving with a number of new \n",
            "developments. Large-scale general language models are an exciting new capability allowing us to add \n",
            "amazing functionality quickly with limited compute and people. Innovation continues with new models\n",
            "and advancements coming in at what seems a weekly basis.\n",
            "\n",
            "This article introduces txtai, an AI-powered search engine that enables Natural Language \n",
            "Understanding (NLU) based search in any application.\n",
            "\n",
            "Introducing txtai\n",
            "txtai builds an AI-powered index over sections of text. txtai supports building text indices to perform \n",
            "similarity searches and create extractive question-answering based systems. txtai also has functionality \n",
            "for zero-shot classification. txtai is open source and available on GitHub.\n",
            "\n",
            "txtai and/or the concepts behind it has already been used to power the Natural Language Processing \n",
            "(NLP) applications listed below:\n",
            "\n",
            "• paperai — AI-powered literature discovery and review engine for medical/scientific papers\n",
            "• tldrstory — AI-powered understanding of headlines and story text\n",
            "• neuspo — Fact-driven, real-time sports event and news site\n",
            "• codequestion — Ask coding questions directly from the terminal\n",
            "\n",
            "Build an Embeddings index\n",
            "For small lists of texts, the method above works. But for larger repositories of documents, it doesn’t \n",
            "make sense to tokenize and convert all embeddings for each query. txtai supports building pre-\n",
            "computed indices which significantly improves performance.\n",
            "\n",
            "Building on the previous example, the following example runs an index method to build and store the \n",
            "text embeddings. In this case, only the query is converted to an embeddings vector each search.\n",
            "\n",
            "[https://github.com/neuml/codequestion](https://github.com/neuml/codequestion) \n",
            "[https://neuspo.com/](https://neuspo.com/) \n",
            "[https://github.com/neuml/tldrstory](https://github.com/neuml/tldrstory) \n",
            "[https://github.com/neuml/paperai](https://github.com/neuml/paperai)\n",
            "[PAGE BREAK]\n",
            "- Introducing txtai, an AI-powered search engine built on Transformers\n",
            "- Add Natural Language Understanding to any application\n",
            "- Introducing txtai\n",
            "- Build an Embeddings index\n"
          ]
        }
      ]
    }
  ]
}