{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Viny2030/UNED/blob/main/Stanza_Beginners_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56LiYCkPM7V_"
      },
      "source": [
        "# Welcome to Stanza!\n",
        "\n",
        "![Latest Version](https://img.shields.io/pypi/v/stanza.svg?colorB=bc4545)\n",
        "![Python Versions](https://img.shields.io/pypi/pyversions/stanza.svg?colorB=bc4545)\n",
        "\n",
        "Stanza is a Python NLP toolkit that supports 60+ human languages. It is built with highly accurate neural network components that enable efficient training and evaluation with your own annotated data, and offers pretrained models on 100 treebanks. Additionally, Stanza provides a stable, officially maintained Python interface to Java Stanford CoreNLP Toolkit.\n",
        "\n",
        "In this tutorial, we will demonstrate how to set up Stanza and annotate text with its native neural network NLP models. For the use of the Python CoreNLP interface, please see other tutorials."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stanza es un conjunto de herramientas de procesamiento de lenguaje natural (PLN) para Python que admite más de 60 lenguajes humanos. Está construido con componentes de redes neuronales de alta precisión que permiten un entrenamiento y una evaluación eficientes con sus propios datos anotados, y ofrece modelos entrenados previamente en 100 bancos de árboles. Además, Stanza proporciona una interfaz de Python estable y con mantenimiento oficial para el conjunto de herramientas Java Stanford CoreNLP.\n",
        "\n",
        "En este tutorial, demostraremos cómo configurar Stanza y anotar texto con sus modelos de PNL de redes neuronales nativos. Para el uso de la interfaz Python CoreNLP, consulte otros tutoriales."
      ],
      "metadata": {
        "id": "J_bdug563i93"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQff4Di5Nnq0"
      },
      "source": [
        "## 1. Installing Stanza\n",
        "\n",
        "Note that Stanza only supports Python 3.6 and above. Installing and importing Stanza are as simple as running the following commands:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Instalación de Stanza**\n",
        "Tenga en cuenta que Stanza solo es compatible con Python 3.6 y versiones posteriores. Instalar e importar Stanza es tan sencillo como ejecutar los siguientes comandos:"
      ],
      "metadata": {
        "id": "ogZcEL1A3s2c"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owSj1UtdEvSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "230fe09e-cc96-494f-d8e8-0f5cb13557e2"
      },
      "source": [
        "# Install; note that the prefix \"!\" is not needed if you are running in a terminal\n",
        "!pip install stanza\n",
        "\n",
        "# Import the package\n",
        "import stanza"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.9.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting emoji (from stanza)\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (4.25.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.4.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.6)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from stanza) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n",
            "Downloading stanza-1.9.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji, stanza\n",
            "Successfully installed emoji-2.14.0 stanza-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stanfordnlp.github.io/stanza/tutorials.html\n"
      ],
      "metadata": {
        "id": "ZZGtp1QW327o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ixllwEKeCJg"
      },
      "source": [
        "### More Information\n",
        "\n",
        "For common troubleshooting, please visit our [troubleshooting page](https://stanfordnlp.github.io/stanfordnlp/installation_usage.html#troubleshooting)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Más información**\n",
        "Para solucionar problemas comunes, visite nuestra página de solución de problemas."
      ],
      "metadata": {
        "id": "0luz1WpK371F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeyPs5ARO79d"
      },
      "source": [
        "## 2. Downloading Models\n",
        "\n",
        "You can download models with the `stanza.download` command. The language can be specified with either a full language name (e.g., \"english\"), or a short code (e.g., \"en\").\n",
        "\n",
        "By default, models will be saved to your `~/stanza_resources` directory. If you want to specify your own path to save the model files, you can pass a `dir=your_path` argument.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Descarga de modelos**\n",
        "Puede descargar modelos con el comando stanza.download. El idioma se puede especificar con el nombre completo del idioma (por ejemplo, \"english\") o con un código corto (por ejemplo, \"en\").\n",
        "\n",
        "De manera predeterminada, los modelos se guardarán en el directorio ~/stanza_resources. Si desea especificar su propia ruta para guardar los archivos de modelos, puede pasar un argumento dir=your_path."
      ],
      "metadata": {
        "id": "rH4OL49s4Ajm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDwRm-KXGcYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fffa2d46-4d86-43c3-e00f-a44ddd1ea591"
      },
      "source": [
        "# Download an English model into the default directory\n",
        "print(\"Downloading English model...\")\n",
        "stanza.download('en')\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading English model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HCfQ0SfdmsU"
      },
      "source": [
        "### More Information\n",
        "\n",
        "Pretrained models are provided for 60+ different languages. For all languages, available models and the corresponding short language codes, please check out the [models page](https://stanfordnlp.github.io/stanza/models.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Más información**\n",
        "Se proporcionan modelos preentrenados para más de 60 idiomas diferentes. Para conocer todos los idiomas, los modelos disponibles y los códigos de idioma cortos correspondientes, consulte la página de modelos."
      ],
      "metadata": {
        "id": "CtZB_6ph4NCn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3-WZJrzWD2o"
      },
      "source": [
        "## 3. Processing Text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrnKl2m3fq2f"
      },
      "source": [
        "### Constructing Pipeline\n",
        "\n",
        "To process a piece of text, you'll need to first construct a `Pipeline` with different `Processor` units. The pipeline is language-specific, so again you'll need to first specify the language (see examples).\n",
        "\n",
        "- By default, the pipeline will include all processors, including tokenization, multi-word token expansion, part-of-speech tagging, lemmatization, dependency parsing and named entity recognition (for supported languages). However, you can always specify what processors you want to include with the `processors` argument.\n",
        "\n",
        "- Stanza's pipeline is CUDA-aware, meaning that a CUDA-device will be used whenever it is available, otherwise CPUs will be used when a GPU is not found. You can force the pipeline to use CPU regardless by setting `use_gpu=False`.\n",
        "\n",
        "- Again, you can suppress all printed messages by setting `verbose=False`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construcción de un pipeline\n",
        "Para procesar un fragmento de texto, primero deberá construir un pipeline con diferentes unidades de procesador. El pipeline es específico del lenguaje, por lo que nuevamente deberá especificar primero el lenguaje (consulte los ejemplos).\n",
        "\n",
        "De manera predeterminada, el pipeline incluirá todos los procesadores, incluida la tokenización, la expansión de tokens de múltiples palabras, el etiquetado de partes del discurso, la lematización, el análisis de dependencias y el reconocimiento de entidades con nombre (para los idiomas admitidos). Sin embargo, siempre puede especificar qué procesadores desea incluir con el argumento de procesadores.\n",
        "\n",
        "El pipeline de Stanza es compatible con CUDA, lo que significa que se utilizará un dispositivo CUDA siempre que esté disponible; de ​​lo contrario, se utilizarán las CPU cuando no se encuentre una GPU. Puede forzar al pipeline a utilizar la CPU independientemente configurando use_gpu=False.\n",
        "\n",
        "Nuevamente, puede suprimir todos los mensajes impresos configurando verbose=False.\n"
      ],
      "metadata": {
        "id": "uMbll46v4S-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch\n",
        "!pip install --upgrade stanza"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auEJ9HBSXMSG",
        "outputId": "ad3662d5-39dd-4f61-fa8f-591327574742"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: stanza in /usr/local/lib/python3.10/dist-packages (1.9.2)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from stanza) (2.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (4.25.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.4.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.6)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from stanza) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbiTSBDPG53o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "11ebec52-8a66-4d34-bc0f-6dce8f5ed15a"
      },
      "source": [
        "# Build an English pipeline, with all processors by default\n",
        "print(\"Building an English pipeline\")\n",
        "en_nlp = stanza.Pipeline('en')\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building an English pipeline\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch._dynamo' has no attribute 'external_utils' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-65d4c1fae084>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build an English pipeline, with all processors by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Building an English pipeline\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0men_nlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang, dir, package, processors, logging_level, verbose, use_gpu, model_dir, download_method, resources_url, resources_branch, resources_version, resources_filepath, proxies, foundation_cache, device, allow_unknown_language, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;31m# try to build processor, throw an exception if there is a requirements issue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                 self.processors[processor_name] = NAME_TO_PROCESSOR_CLASS[processor_name](config=curr_processor_config,\n\u001b[0m\u001b[1;32m    309\u001b[0m                                                                                           \u001b[0mpipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                                                                           device=self.device)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/pipeline/processor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, pipeline, device)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_variant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_up_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# build the final config for the processor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/pipeline/tokenize_processor.py\u001b[0m in \u001b[0;36m_set_up_model\u001b[0;34m(self, config, pipeline, device)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# get and typecheck the postprocessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/models/tokenization/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, vocab, lexicon, dictionary, model_file, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat_funcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feat_funcs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lang'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# language determines how token normalization is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/models/common/utils.py\u001b[0m in \u001b[0;36mget_optimizer\u001b[0;34m(name, model, lr, betas, eps, momentum, weight_decay, bert_learning_rate, bert_weight_decay, charlm_learning_rate, is_peft, bert_finetune_layers, opt_logger)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mextra_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weight_decay\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_logger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_split_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_learning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_weight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharlm_learning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_finetune_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/models/common/utils.py\u001b[0m in \u001b[0;36mdispatch_optimizer\u001b[0;34m(name, parameters, opt_logger, lr, betas, eps, momentum, **extra_args)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mopt_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Building Adam with lr=%f, betas=%s, eps=%f%s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_logging\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'adamw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mopt_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Building AdamW with lr=%f, betas=%s, eps=%f%s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_logging\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         )\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dynamo_disable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisable_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCapturedTraceback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_traceback_short\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbytecode_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mremove_dead_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_pointless_jumps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m from .bytecode_transformation import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mresume_execution\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTORCH_DYNAMO_RESUME_IN_PREFIX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNP_SUPPORTED_MODULES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munwrap_if_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m from .variables import (\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mBuiltinVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mFunctionalCallVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/variables/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mUntypedStorageVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m )\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchCtxManagerClassVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTorchInGraphFunctionVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m from .user_defined import (\n\u001b[1;32m    106\u001b[0m     \u001b[0mMutableMappingVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/variables/torch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbolic_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fx_tracing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_onnx_export\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compiling\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compiling\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compiling\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torch._dynamo' has no attribute 'external_utils' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go123Bx8e1wt"
      },
      "source": [
        "### Annotating Text\n",
        "\n",
        "After a pipeline is successfully constructed, you can get annotations of a piece of text simply by passing the string into the pipeline object. The pipeline will return a `Document` object, which can be used to access detailed annotations from. For example:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Anotación de texto**\n",
        "Una vez que se ha creado correctamente una secuencia de comandos, puede obtener anotaciones de un fragmento de texto simplemente pasando la cadena al objeto de secuencia de comandos. La secuencia de comandos devolverá un objeto Document, que se puede utilizar para acceder a anotaciones detalladas. Por ejemplo:"
      ],
      "metadata": {
        "id": "bl8ql34h4cpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NzADD0125o4n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ROSNcqv5sr_",
        "outputId": "85da1839-2cf9-4669-d928-840a6c4ede26"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##input = pd.read_csv('https://raw.githubusercontent.com/Viny2030/datasets/refs/heads/main/input.txt', sep='\\t', header=None)"
      ],
      "metadata": {
        "id": "tRUBe9up5iTQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##input"
      ],
      "metadata": {
        "id": "3XVZ05C76QLn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "nlp = stanza.Pipeline(lang='en')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "HujcOOqYXiwk",
        "outputId": "b30594d4-0b2f-4781-cfb8-66d33a89faec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch._dynamo' has no attribute 'external_utils' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-1f3fbb2fd790>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang, dir, package, processors, logging_level, verbose, use_gpu, model_dir, download_method, resources_url, resources_branch, resources_version, resources_filepath, proxies, foundation_cache, device, allow_unknown_language, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;31m# try to build processor, throw an exception if there is a requirements issue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                 self.processors[processor_name] = NAME_TO_PROCESSOR_CLASS[processor_name](config=curr_processor_config,\n\u001b[0m\u001b[1;32m    309\u001b[0m                                                                                           \u001b[0mpipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                                                                           device=self.device)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/pipeline/processor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, pipeline, device)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_variant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_up_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# build the final config for the processor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/pipeline/tokenize_processor.py\u001b[0m in \u001b[0;36m_set_up_model\u001b[0;34m(self, config, pipeline, device)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# get and typecheck the postprocessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/models/tokenization/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, vocab, lexicon, dictionary, model_file, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat_funcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feat_funcs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lang'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# language determines how token normalization is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/models/common/utils.py\u001b[0m in \u001b[0;36mget_optimizer\u001b[0;34m(name, model, lr, betas, eps, momentum, weight_decay, bert_learning_rate, bert_weight_decay, charlm_learning_rate, is_peft, bert_finetune_layers, opt_logger)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mextra_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weight_decay\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_logger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_split_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_learning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_weight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharlm_learning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_finetune_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/models/common/utils.py\u001b[0m in \u001b[0;36mdispatch_optimizer\u001b[0;34m(name, parameters, opt_logger, lr, betas, eps, momentum, **extra_args)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mopt_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Building Adam with lr=%f, betas=%s, eps=%f%s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_logging\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'adamw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mopt_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Building AdamW with lr=%f, betas=%s, eps=%f%s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_logging\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         )\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dynamo_disable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisable_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCapturedTraceback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_traceback_short\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbytecode_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mremove_dead_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_pointless_jumps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m from .bytecode_transformation import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mresume_execution\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTORCH_DYNAMO_RESUME_IN_PREFIX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNP_SUPPORTED_MODULES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munwrap_if_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m from .variables import (\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mBuiltinVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mFunctionalCallVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/variables/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mUntypedStorageVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m )\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchCtxManagerClassVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTorchInGraphFunctionVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m from .user_defined import (\n\u001b[1;32m    106\u001b[0m     \u001b[0mMutableMappingVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/variables/torch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbolic_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fx_tracing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_onnx_export\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compiling\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compiling\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compiling\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torch._dynamo' has no attribute 'external_utils' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing English text\n",
        "doc = en_nlp(\"Jane bought me these books,Jane bought a book for me, She dropped a line to him. Thank you,She sleeps,I sleep a lot,I was born in Madrid,the cat was chased by the dog,I was born in Madrid during 1995,Out of all this , something good will come,Susan left after the rehearsal. She did it well,She sleeps during the morning, but she sleeps\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Uq8d1Zqv6Tku",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "f06af4a9-9e14-4200-d8b7-dcc002d5fee8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'en_nlp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-95c9115d81d0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Processing English text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_nlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Jane bought me these books,Jane bought a book for me, She dropped a line to him. Thank you,She sleeps,I sleep a lot,I was born in Madrid,the cat was chased by the dog,I was born in Madrid during 1995,Out of all this , something good will come,Susan left after the rehearsal. She did it well,She sleeps during the morning, but she sleeps\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'en_nlp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PwwU2rf6feu",
        "outputId": "fb0f824b-5f23-47c3-ed22-b6b70367659d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\n",
              "  [\n",
              "    {\n",
              "      \"id\": 1,\n",
              "      \"text\": \"Jane\",\n",
              "      \"lemma\": \"Jane\",\n",
              "      \"upos\": \"PROPN\",\n",
              "      \"xpos\": \"NNP\",\n",
              "      \"feats\": \"Number=Sing\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"nsubj\",\n",
              "      \"start_char\": 0,\n",
              "      \"end_char\": 4,\n",
              "      \"ner\": \"S-PERSON\",\n",
              "      \"multi_ner\": [\n",
              "        \"S-PERSON\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 2,\n",
              "      \"text\": \"bought\",\n",
              "      \"lemma\": \"buy\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VBD\",\n",
              "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
              "      \"head\": 0,\n",
              "      \"deprel\": \"root\",\n",
              "      \"start_char\": 5,\n",
              "      \"end_char\": 11,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 3,\n",
              "      \"text\": \"me\",\n",
              "      \"lemma\": \"I\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"PRP\",\n",
              "      \"feats\": \"Case=Acc|Number=Sing|Person=1|PronType=Prs\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"iobj\",\n",
              "      \"start_char\": 12,\n",
              "      \"end_char\": 14,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 4,\n",
              "      \"text\": \"these\",\n",
              "      \"lemma\": \"this\",\n",
              "      \"upos\": \"DET\",\n",
              "      \"xpos\": \"DT\",\n",
              "      \"feats\": \"Number=Plur|PronType=Dem\",\n",
              "      \"head\": 5,\n",
              "      \"deprel\": \"det\",\n",
              "      \"start_char\": 15,\n",
              "      \"end_char\": 20,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 5,\n",
              "      \"text\": \"books\",\n",
              "      \"lemma\": \"book\",\n",
              "      \"upos\": \"NOUN\",\n",
              "      \"xpos\": \"NNS\",\n",
              "      \"feats\": \"Number=Plur\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"obj\",\n",
              "      \"start_char\": 21,\n",
              "      \"end_char\": 26,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 6,\n",
              "      \"text\": \",\",\n",
              "      \"lemma\": \",\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \",\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 26,\n",
              "      \"end_char\": 27,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 7,\n",
              "      \"text\": \"Jane\",\n",
              "      \"lemma\": \"Jane\",\n",
              "      \"upos\": \"PROPN\",\n",
              "      \"xpos\": \"NNP\",\n",
              "      \"feats\": \"Number=Sing\",\n",
              "      \"head\": 8,\n",
              "      \"deprel\": \"nsubj\",\n",
              "      \"start_char\": 27,\n",
              "      \"end_char\": 31,\n",
              "      \"ner\": \"S-PERSON\",\n",
              "      \"multi_ner\": [\n",
              "        \"S-PERSON\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 8,\n",
              "      \"text\": \"bought\",\n",
              "      \"lemma\": \"buy\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VBD\",\n",
              "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"parataxis\",\n",
              "      \"start_char\": 32,\n",
              "      \"end_char\": 38,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 9,\n",
              "      \"text\": \"a\",\n",
              "      \"lemma\": \"a\",\n",
              "      \"upos\": \"DET\",\n",
              "      \"xpos\": \"DT\",\n",
              "      \"feats\": \"Definite=Ind|PronType=Art\",\n",
              "      \"head\": 10,\n",
              "      \"deprel\": \"det\",\n",
              "      \"start_char\": 39,\n",
              "      \"end_char\": 40,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 10,\n",
              "      \"text\": \"book\",\n",
              "      \"lemma\": \"book\",\n",
              "      \"upos\": \"NOUN\",\n",
              "      \"xpos\": \"NN\",\n",
              "      \"feats\": \"Number=Sing\",\n",
              "      \"head\": 8,\n",
              "      \"deprel\": \"obj\",\n",
              "      \"start_char\": 41,\n",
              "      \"end_char\": 45,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 11,\n",
              "      \"text\": \"for\",\n",
              "      \"lemma\": \"for\",\n",
              "      \"upos\": \"ADP\",\n",
              "      \"xpos\": \"IN\",\n",
              "      \"head\": 12,\n",
              "      \"deprel\": \"case\",\n",
              "      \"start_char\": 46,\n",
              "      \"end_char\": 49,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 12,\n",
              "      \"text\": \"me\",\n",
              "      \"lemma\": \"I\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"PRP\",\n",
              "      \"feats\": \"Case=Acc|Number=Sing|Person=1|PronType=Prs\",\n",
              "      \"head\": 8,\n",
              "      \"deprel\": \"obl\",\n",
              "      \"start_char\": 50,\n",
              "      \"end_char\": 52,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 13,\n",
              "      \"text\": \",\",\n",
              "      \"lemma\": \",\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \",\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 52,\n",
              "      \"end_char\": 53,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 14,\n",
              "      \"text\": \"She\",\n",
              "      \"lemma\": \"she\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"PRP\",\n",
              "      \"feats\": \"Case=Nom|Gender=Fem|Number=Sing|Person=3|PronType=Prs\",\n",
              "      \"head\": 15,\n",
              "      \"deprel\": \"nsubj\",\n",
              "      \"start_char\": 54,\n",
              "      \"end_char\": 57,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 15,\n",
              "      \"text\": \"dropped\",\n",
              "      \"lemma\": \"drop\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VBD\",\n",
              "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"parataxis\",\n",
              "      \"start_char\": 58,\n",
              "      \"end_char\": 65,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 16,\n",
              "      \"text\": \"a\",\n",
              "      \"lemma\": \"a\",\n",
              "      \"upos\": \"DET\",\n",
              "      \"xpos\": \"DT\",\n",
              "      \"feats\": \"Definite=Ind|PronType=Art\",\n",
              "      \"head\": 17,\n",
              "      \"deprel\": \"det\",\n",
              "      \"start_char\": 66,\n",
              "      \"end_char\": 67,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 17,\n",
              "      \"text\": \"line\",\n",
              "      \"lemma\": \"line\",\n",
              "      \"upos\": \"NOUN\",\n",
              "      \"xpos\": \"NN\",\n",
              "      \"feats\": \"Number=Sing\",\n",
              "      \"head\": 15,\n",
              "      \"deprel\": \"obj\",\n",
              "      \"start_char\": 68,\n",
              "      \"end_char\": 72,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 18,\n",
              "      \"text\": \"to\",\n",
              "      \"lemma\": \"to\",\n",
              "      \"upos\": \"ADP\",\n",
              "      \"xpos\": \"IN\",\n",
              "      \"head\": 19,\n",
              "      \"deprel\": \"case\",\n",
              "      \"start_char\": 73,\n",
              "      \"end_char\": 75,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 19,\n",
              "      \"text\": \"him\",\n",
              "      \"lemma\": \"he\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"PRP\",\n",
              "      \"feats\": \"Case=Acc|Gender=Masc|Number=Sing|Person=3|PronType=Prs\",\n",
              "      \"head\": 15,\n",
              "      \"deprel\": \"obl\",\n",
              "      \"start_char\": 76,\n",
              "      \"end_char\": 79,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 20,\n",
              "      \"text\": \".\",\n",
              "      \"lemma\": \".\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \".\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 79,\n",
              "      \"end_char\": 80,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    }\n",
              "  ],\n",
              "  [\n",
              "    {\n",
              "      \"id\": 1,\n",
              "      \"text\": \"Thank\",\n",
              "      \"lemma\": \"thank\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VBP\",\n",
              "      \"feats\": \"Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin\",\n",
              "      \"head\": 0,\n",
              "      \"deprel\": \"root\",\n",
              "      \"start_char\": 81,\n",
              "      \"end_char\": 86,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 2,\n",
              "      \"text\": \"you\",\n",
              "      \"lemma\": \"you\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"PRP\",\n",
              "      \"feats\": \"Case=Acc|Person=2|PronType=Prs\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"obj\",\n",
              "      \"start_char\": 87,\n",
              "      \"end_char\": 90,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 3,\n",
              "      \"text\": \",\",\n",
              "      \"lemma\": \",\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \",\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 90,\n",
              "      \"end_char\": 91,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 4,\n",
              "      \"text\": \"She\",\n",
              "      \"lemma\": \"she\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"PRP\",\n",
              "      \"feats\": \"Case=Nom|Gender=Fem|Number=Sing|Person=3|PronType=Prs\",\n",
              "      \"head\": 5,\n",
              "      \"deprel\": \"nsubj\",\n",
              "      \"start_char\": 91,\n",
              "      \"end_char\": 94,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 5,\n",
              "      \"text\": \"sleeps\",\n",
              "      \"lemma\": \"sleep\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VBZ\",\n",
              "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"parataxis\",\n",
              "      \"start_char\": 95,\n",
              "      \"end_char\": 101,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 6,\n",
              "      \"text\": \",\",\n",
              "      \"lemma\": \",\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \",\",\n",
              "      \"head\": 8,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 101,\n",
              "      \"end_char\": 102,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 7,\n",
              "      \"text\": \"I\",\n",
              "      \"lemma\": \"I\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"PRP\",\n",
              "      \"feats\": \"Case=Nom|Number=Sing|Person=1|PronType=Prs\",\n",
              "      \"head\": 8,\n",
              "      \"deprel\": \"nsubj\",\n",
              "      \"start_char\": 102,\n",
              "      \"end_char\": 103,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 8,\n",
              "      \"text\": \"sleep\",\n",
              "      \"lemma\": \"sleep\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VBP\",\n",
              "      \"feats\": \"Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"parataxis\",\n",
              "      \"start_char\": 104,\n",
              "      \"end_char\": 109,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 9,\n",
              "      \"text\": \"a\",\n",
              "      \"lemma\": \"a\",\n",
              "      \"upos\": \"DET\",\n",
              "      \"xpos\": \"DT\",\n",
              "      \"feats\": \"Definite=Ind|PronType=Art\",\n",
              "      \"head\": 10,\n",
              "      \"deprel\": \"det\",\n",
              "      \"start_char\": 110,\n",
              "      \"end_char\": 111,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 10,\n",
              "      \"text\": \"lot\",\n",
              "      \"lemma\": \"lot\",\n",
              "      \"upos\": \"NOUN\",\n",
              "      \"xpos\": \"NN\",\n",
              "      \"feats\": \"Number=Sing\",\n",
              "      \"head\": 8,\n",
              "      \"deprel\": \"obl:npmod\",\n",
              "      \"start_char\": 112,\n",
              "      \"end_char\": 115,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 11,\n",
              "      \"text\": \",\",\n",
              "      \"lemma\": \",\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \",\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 115,\n",
              "      \"end_char\": 116,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 12,\n",
              "      \"text\": \"I\",\n",
              "      \"lemma\": \"I\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"PRP\",\n",
              "      \"feats\": \"Case=Nom|Number=Sing|Person=1|PronType=Prs\",\n",
              "      \"head\": 14,\n",
              "      \"deprel\": \"nsubj:pass\",\n",
              "      \"start_char\": 116,\n",
              "      \"end_char\": 117,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 13,\n",
              "      \"text\": \"was\",\n",
              "      \"lemma\": \"be\",\n",
              "      \"upos\": \"AUX\",\n",
              "      \"xpos\": \"VBD\",\n",
              "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
              "      \"head\": 14,\n",
              "      \"deprel\": \"aux:pass\",\n",
              "      \"start_char\": 118,\n",
              "      \"end_char\": 121,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 14,\n",
              "      \"text\": \"born\",\n",
              "      \"lemma\": \"bear\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VBN\",\n",
              "      \"feats\": \"Tense=Past|VerbForm=Part|Voice=Pass\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"parataxis\",\n",
              "      \"start_char\": 122,\n",
              "      \"end_char\": 126,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 15,\n",
              "      \"text\": \"in\",\n",
              "      \"lemma\": \"in\",\n",
              "      \"upos\": \"ADP\",\n",
              "      \"xpos\": \"IN\",\n",
              "      \"head\": 16,\n",
              "      \"deprel\": \"case\",\n",
              "      \"start_char\": 127,\n",
              "      \"end_char\": 129,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 16,\n",
              "      \"text\": \"Madrid\",\n",
              "      \"lemma\": \"Madrid\",\n",
              "      \"upos\": \"PROPN\",\n",
              "      \"xpos\": \"NNP\",\n",
              "      \"feats\": \"Number=Sing\",\n",
              "      \"head\": 14,\n",
              "      \"deprel\": \"obl\",\n",
              "      \"start_char\": 130,\n",
              "      \"end_char\": 136,\n",
              "      \"ner\": \"S-GPE\",\n",
              "      \"multi_ner\": [\n",
              "        \"S-GPE\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 17,\n",
              "      \"text\": \",\",\n",
              "      \"lemma\": \",\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \",\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 136,\n",
              "      \"end_char\": 137,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 18,\n",
              "      \"text\": \"the\",\n",
              "      \"lemma\": \"the\",\n",
              "      \"upos\": \"DET\",\n",
              "      \"xpos\": \"DT\",\n",
              "      \"feats\": \"Definite=Def|PronType=Art\",\n",
              "      \"head\": 19,\n",
              "      \"deprel\": \"det\",\n",
              "      \"start_char\": 137,\n",
              "      \"end_char\": 140,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 19,\n",
              "      \"text\": \"cat\",\n",
              "      \"lemma\": \"cat\",\n",
              "      \"upos\": \"NOUN\",\n",
              "      \"xpos\": \"NN\",\n",
              "      \"feats\": \"Number=Sing\",\n",
              "      \"head\": 21,\n",
              "      \"deprel\": \"nsubj:pass\",\n",
              "      \"start_char\": 141,\n",
              "      \"end_char\": 144,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 20,\n",
              "      \"text\": \"was\",\n",
              "      \"lemma\": \"be\",\n",
              "      \"upos\": \"AUX\",\n",
              "      \"xpos\": \"VBD\",\n",
              "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
              "      \"head\": 21,\n",
              "      \"deprel\": \"aux:pass\",\n",
              "      \"start_char\": 145,\n",
              "      \"end_char\": 148,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 21,\n",
              "      \"text\": \"chased\",\n",
              "      \"lemma\": \"chase\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VBN\",\n",
              "      \"feats\": \"Tense=Past|VerbForm=Part|Voice=Pass\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"parataxis\",\n",
              "      \"start_char\": 149,\n",
              "      \"end_char\": 155,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 22,\n",
              "      \"text\": \"by\",\n",
              "      \"lemma\": \"by\",\n",
              "      \"upos\": \"ADP\",\n",
              "      \"xpos\": \"IN\",\n",
              "      \"head\": 24,\n",
              "      \"deprel\": \"case\",\n",
              "      \"start_char\": 156,\n",
              "      \"end_char\": 158,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 23,\n",
              "      \"text\": \"the\",\n",
              "      \"lemma\": \"the\",\n",
              "      \"upos\": \"DET\",\n",
              "      \"xpos\": \"DT\",\n",
              "      \"feats\": \"Definite=Def|PronType=Art\",\n",
              "      \"head\": 24,\n",
              "      \"deprel\": \"det\",\n",
              "      \"start_char\": 159,\n",
              "      \"end_char\": 162,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 24,\n",
              "      \"text\": \"dog\",\n",
              "      \"lemma\": \"dog\",\n",
              "      \"upos\": \"NOUN\",\n",
              "      \"xpos\": \"NN\",\n",
              "      \"feats\": \"Number=Sing\",\n",
              "      \"head\": 21,\n",
              "      \"deprel\": \"obl:agent\",\n",
              "      \"start_char\": 163,\n",
              "      \"end_char\": 166,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 25,\n",
              "      \"text\": \",\",\n",
              "      \"lemma\": \",\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \",\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 166,\n",
              "      \"end_char\": 167,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 26,\n",
              "      \"text\": \"I\",\n",
              "      \"lemma\": \"I\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"PRP\",\n",
              "      \"feats\": \"Case=Nom|Number=Sing|Person=1|PronType=Prs\",\n",
              "      \"head\": 28,\n",
              "      \"deprel\": \"nsubj:pass\",\n",
              "      \"start_char\": 167,\n",
              "      \"end_char\": 168,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 27,\n",
              "      \"text\": \"was\",\n",
              "      \"lemma\": \"be\",\n",
              "      \"upos\": \"AUX\",\n",
              "      \"xpos\": \"VBD\",\n",
              "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
              "      \"head\": 28,\n",
              "      \"deprel\": \"aux:pass\",\n",
              "      \"start_char\": 169,\n",
              "      \"end_char\": 172,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 28,\n",
              "      \"text\": \"born\",\n",
              "      \"lemma\": \"bear\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VBN\",\n",
              "      \"feats\": \"Tense=Past|VerbForm=Part|Voice=Pass\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"parataxis\",\n",
              "      \"start_char\": 173,\n",
              "      \"end_char\": 177,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 29,\n",
              "      \"text\": \"in\",\n",
              "      \"lemma\": \"in\",\n",
              "      \"upos\": \"ADP\",\n",
              "      \"xpos\": \"IN\",\n",
              "      \"head\": 30,\n",
              "      \"deprel\": \"case\",\n",
              "      \"start_char\": 178,\n",
              "      \"end_char\": 180,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 30,\n",
              "      \"text\": \"Madrid\",\n",
              "      \"lemma\": \"Madrid\",\n",
              "      \"upos\": \"PROPN\",\n",
              "      \"xpos\": \"NNP\",\n",
              "      \"feats\": \"Number=Sing\",\n",
              "      \"head\": 28,\n",
              "      \"deprel\": \"obl\",\n",
              "      \"start_char\": 181,\n",
              "      \"end_char\": 187,\n",
              "      \"ner\": \"S-GPE\",\n",
              "      \"multi_ner\": [\n",
              "        \"S-GPE\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 31,\n",
              "      \"text\": \"during\",\n",
              "      \"lemma\": \"during\",\n",
              "      \"upos\": \"ADP\",\n",
              "      \"xpos\": \"IN\",\n",
              "      \"head\": 32,\n",
              "      \"deprel\": \"case\",\n",
              "      \"start_char\": 188,\n",
              "      \"end_char\": 194,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 32,\n",
              "      \"text\": \"1995\",\n",
              "      \"lemma\": \"1995\",\n",
              "      \"upos\": \"NUM\",\n",
              "      \"xpos\": \"CD\",\n",
              "      \"feats\": \"NumForm=Digit|NumType=Card\",\n",
              "      \"head\": 28,\n",
              "      \"deprel\": \"obl\",\n",
              "      \"start_char\": 195,\n",
              "      \"end_char\": 199,\n",
              "      \"ner\": \"S-DATE\",\n",
              "      \"multi_ner\": [\n",
              "        \"S-DATE\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 33,\n",
              "      \"text\": \",\",\n",
              "      \"lemma\": \",\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \",\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 199,\n",
              "      \"end_char\": 200,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 34,\n",
              "      \"text\": \"Out\",\n",
              "      \"lemma\": \"out\",\n",
              "      \"upos\": \"ADP\",\n",
              "      \"xpos\": \"IN\",\n",
              "      \"head\": 37,\n",
              "      \"deprel\": \"case\",\n",
              "      \"start_char\": 200,\n",
              "      \"end_char\": 203,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 35,\n",
              "      \"text\": \"of\",\n",
              "      \"lemma\": \"of\",\n",
              "      \"upos\": \"ADP\",\n",
              "      \"xpos\": \"IN\",\n",
              "      \"head\": 34,\n",
              "      \"deprel\": \"fixed\",\n",
              "      \"start_char\": 204,\n",
              "      \"end_char\": 206,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 36,\n",
              "      \"text\": \"all\",\n",
              "      \"lemma\": \"all\",\n",
              "      \"upos\": \"DET\",\n",
              "      \"xpos\": \"PDT\",\n",
              "      \"head\": 37,\n",
              "      \"deprel\": \"det:predet\",\n",
              "      \"start_char\": 207,\n",
              "      \"end_char\": 210,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 37,\n",
              "      \"text\": \"this\",\n",
              "      \"lemma\": \"this\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"DT\",\n",
              "      \"feats\": \"Number=Sing|PronType=Dem\",\n",
              "      \"head\": 42,\n",
              "      \"deprel\": \"obl\",\n",
              "      \"start_char\": 211,\n",
              "      \"end_char\": 215,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 38,\n",
              "      \"text\": \",\",\n",
              "      \"lemma\": \",\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \",\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 216,\n",
              "      \"end_char\": 217,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 39,\n",
              "      \"text\": \"something\",\n",
              "      \"lemma\": \"something\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"NN\",\n",
              "      \"feats\": \"Number=Sing|PronType=Ind\",\n",
              "      \"head\": 42,\n",
              "      \"deprel\": \"nsubj\",\n",
              "      \"start_char\": 218,\n",
              "      \"end_char\": 227,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 40,\n",
              "      \"text\": \"good\",\n",
              "      \"lemma\": \"good\",\n",
              "      \"upos\": \"ADJ\",\n",
              "      \"xpos\": \"JJ\",\n",
              "      \"feats\": \"Degree=Pos\",\n",
              "      \"head\": 39,\n",
              "      \"deprel\": \"amod\",\n",
              "      \"start_char\": 228,\n",
              "      \"end_char\": 232,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 41,\n",
              "      \"text\": \"will\",\n",
              "      \"lemma\": \"will\",\n",
              "      \"upos\": \"AUX\",\n",
              "      \"xpos\": \"MD\",\n",
              "      \"feats\": \"VerbForm=Fin\",\n",
              "      \"head\": 42,\n",
              "      \"deprel\": \"aux\",\n",
              "      \"start_char\": 233,\n",
              "      \"end_char\": 237,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 42,\n",
              "      \"text\": \"come\",\n",
              "      \"lemma\": \"come\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VB\",\n",
              "      \"feats\": \"VerbForm=Inf\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"parataxis\",\n",
              "      \"start_char\": 238,\n",
              "      \"end_char\": 242,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 43,\n",
              "      \"text\": \",\",\n",
              "      \"lemma\": \",\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \",\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 242,\n",
              "      \"end_char\": 243,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 44,\n",
              "      \"text\": \"Susan\",\n",
              "      \"lemma\": \"Susan\",\n",
              "      \"upos\": \"PROPN\",\n",
              "      \"xpos\": \"NNP\",\n",
              "      \"feats\": \"Number=Sing\",\n",
              "      \"head\": 45,\n",
              "      \"deprel\": \"nsubj\",\n",
              "      \"start_char\": 243,\n",
              "      \"end_char\": 248,\n",
              "      \"ner\": \"S-PERSON\",\n",
              "      \"multi_ner\": [\n",
              "        \"S-PERSON\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 45,\n",
              "      \"text\": \"left\",\n",
              "      \"lemma\": \"leave\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VBD\",\n",
              "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"parataxis\",\n",
              "      \"start_char\": 249,\n",
              "      \"end_char\": 253,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 46,\n",
              "      \"text\": \"after\",\n",
              "      \"lemma\": \"after\",\n",
              "      \"upos\": \"ADP\",\n",
              "      \"xpos\": \"IN\",\n",
              "      \"head\": 48,\n",
              "      \"deprel\": \"case\",\n",
              "      \"start_char\": 254,\n",
              "      \"end_char\": 259,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 47,\n",
              "      \"text\": \"the\",\n",
              "      \"lemma\": \"the\",\n",
              "      \"upos\": \"DET\",\n",
              "      \"xpos\": \"DT\",\n",
              "      \"feats\": \"Definite=Def|PronType=Art\",\n",
              "      \"head\": 48,\n",
              "      \"deprel\": \"det\",\n",
              "      \"start_char\": 260,\n",
              "      \"end_char\": 263,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 48,\n",
              "      \"text\": \"rehearsal\",\n",
              "      \"lemma\": \"rehearsal\",\n",
              "      \"upos\": \"NOUN\",\n",
              "      \"xpos\": \"NN\",\n",
              "      \"feats\": \"Number=Sing\",\n",
              "      \"head\": 45,\n",
              "      \"deprel\": \"obl\",\n",
              "      \"start_char\": 264,\n",
              "      \"end_char\": 273,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 49,\n",
              "      \"text\": \".\",\n",
              "      \"lemma\": \".\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \".\",\n",
              "      \"head\": 1,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 273,\n",
              "      \"end_char\": 274,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    }\n",
              "  ],\n",
              "  [\n",
              "    {\n",
              "      \"id\": 1,\n",
              "      \"text\": \"She\",\n",
              "      \"lemma\": \"she\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"PRP\",\n",
              "      \"feats\": \"Case=Nom|Gender=Fem|Number=Sing|Person=3|PronType=Prs\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"nsubj\",\n",
              "      \"start_char\": 275,\n",
              "      \"end_char\": 278,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 2,\n",
              "      \"text\": \"did\",\n",
              "      \"lemma\": \"do\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VBD\",\n",
              "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
              "      \"head\": 0,\n",
              "      \"deprel\": \"root\",\n",
              "      \"start_char\": 279,\n",
              "      \"end_char\": 282,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 3,\n",
              "      \"text\": \"it\",\n",
              "      \"lemma\": \"it\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"PRP\",\n",
              "      \"feats\": \"Case=Acc|Gender=Neut|Number=Sing|Person=3|PronType=Prs\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"obj\",\n",
              "      \"start_char\": 283,\n",
              "      \"end_char\": 285,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 4,\n",
              "      \"text\": \"well\",\n",
              "      \"lemma\": \"well\",\n",
              "      \"upos\": \"ADV\",\n",
              "      \"xpos\": \"RB\",\n",
              "      \"feats\": \"Degree=Pos\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"advmod\",\n",
              "      \"start_char\": 286,\n",
              "      \"end_char\": 290,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 5,\n",
              "      \"text\": \",\",\n",
              "      \"lemma\": \",\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \",\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 290,\n",
              "      \"end_char\": 291,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 6,\n",
              "      \"text\": \"She\",\n",
              "      \"lemma\": \"she\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"PRP\",\n",
              "      \"feats\": \"Case=Nom|Gender=Fem|Number=Sing|Person=3|PronType=Prs\",\n",
              "      \"head\": 7,\n",
              "      \"deprel\": \"nsubj\",\n",
              "      \"start_char\": 291,\n",
              "      \"end_char\": 294,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 7,\n",
              "      \"text\": \"sleeps\",\n",
              "      \"lemma\": \"sleep\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VBZ\",\n",
              "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"parataxis\",\n",
              "      \"start_char\": 295,\n",
              "      \"end_char\": 301,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 8,\n",
              "      \"text\": \"during\",\n",
              "      \"lemma\": \"during\",\n",
              "      \"upos\": \"ADP\",\n",
              "      \"xpos\": \"IN\",\n",
              "      \"head\": 10,\n",
              "      \"deprel\": \"case\",\n",
              "      \"start_char\": 302,\n",
              "      \"end_char\": 308,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 9,\n",
              "      \"text\": \"the\",\n",
              "      \"lemma\": \"the\",\n",
              "      \"upos\": \"DET\",\n",
              "      \"xpos\": \"DT\",\n",
              "      \"feats\": \"Definite=Def|PronType=Art\",\n",
              "      \"head\": 10,\n",
              "      \"deprel\": \"det\",\n",
              "      \"start_char\": 309,\n",
              "      \"end_char\": 312,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 10,\n",
              "      \"text\": \"morning\",\n",
              "      \"lemma\": \"morning\",\n",
              "      \"upos\": \"NOUN\",\n",
              "      \"xpos\": \"NN\",\n",
              "      \"feats\": \"Number=Sing\",\n",
              "      \"head\": 7,\n",
              "      \"deprel\": \"obl\",\n",
              "      \"start_char\": 313,\n",
              "      \"end_char\": 320,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": 11,\n",
              "      \"text\": \",\",\n",
              "      \"lemma\": \",\",\n",
              "      \"upos\": \"PUNCT\",\n",
              "      \"xpos\": \",\",\n",
              "      \"head\": 14,\n",
              "      \"deprel\": \"punct\",\n",
              "      \"start_char\": 320,\n",
              "      \"end_char\": 321,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 12,\n",
              "      \"text\": \"but\",\n",
              "      \"lemma\": \"but\",\n",
              "      \"upos\": \"CCONJ\",\n",
              "      \"xpos\": \"CC\",\n",
              "      \"head\": 14,\n",
              "      \"deprel\": \"cc\",\n",
              "      \"start_char\": 322,\n",
              "      \"end_char\": 325,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 13,\n",
              "      \"text\": \"she\",\n",
              "      \"lemma\": \"she\",\n",
              "      \"upos\": \"PRON\",\n",
              "      \"xpos\": \"PRP\",\n",
              "      \"feats\": \"Case=Nom|Gender=Fem|Number=Sing|Person=3|PronType=Prs\",\n",
              "      \"head\": 14,\n",
              "      \"deprel\": \"nsubj\",\n",
              "      \"start_char\": 326,\n",
              "      \"end_char\": 329,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ]\n",
              "    },\n",
              "    {\n",
              "      \"id\": 14,\n",
              "      \"text\": \"sleeps\",\n",
              "      \"lemma\": \"sleep\",\n",
              "      \"upos\": \"VERB\",\n",
              "      \"xpos\": \"VBZ\",\n",
              "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
              "      \"head\": 2,\n",
              "      \"deprel\": \"conj\",\n",
              "      \"start_char\": 330,\n",
              "      \"end_char\": 336,\n",
              "      \"ner\": \"O\",\n",
              "      \"multi_ner\": [\n",
              "        \"O\"\n",
              "      ],\n",
              "      \"misc\": \"SpaceAfter=No\"\n",
              "    }\n",
              "  ]\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DavwCP9egzNZ"
      },
      "source": [
        "### More Information\n",
        "\n",
        "For more information on how to construct a pipeline and information on different processors, please visit our [pipeline page](https://stanfordnlp.github.io/stanfordnlp/pipeline.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Más información**\n",
        "Para obtener más información sobre cómo construir un pipeline e información sobre diferentes procesadores, visite nuestra página de pipelines."
      ],
      "metadata": {
        "id": "rAi8fexz4oLf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_PYLEGziQWR"
      },
      "source": [
        "## 4. Accessing Annotations\n",
        "\n",
        "Annotations can be accessed from the returned `Document` object.\n",
        "\n",
        "A `Document` contains a list of `Sentence`s, and a `Sentence` contains a list of `Token`s and `Word`s. For the most part `Token`s and `Word`s overlap, but some tokens can be divided into mutiple words, for instance the French token `aux` is divided into the words `à` and `les`, while in English a word and a token are equivalent. Note that dependency parses are derived over `Word`s.\n",
        "\n",
        "Additionally, a `Span` object is used to represent annotations that are part of a document, such as named entity mentions.\n",
        "\n",
        "\n",
        "The following example iterate over all English sentences and words, and print the word information one by one:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Acceso a anotaciones\n",
        "Se puede acceder a las anotaciones desde el objeto Document devuelto.\n",
        "\n",
        "Un Document contiene una lista de Sentences y una Sentence contiene una lista de Tokens y Words. En su mayor parte, los Tokens y Words se superponen, pero algunos tokens se pueden dividir en varias palabras, por ejemplo, el token francés aux se divide en las palabras à y les, mientras que en inglés una palabra y un token son equivalentes. Tenga en cuenta que los análisis de dependencia se derivan sobre Words.\n",
        "\n",
        "Además, se utiliza un objeto Span para representar anotaciones que forman parte de un documento, como menciones de entidades con nombre.\n",
        "\n",
        "El siguiente ejemplo itera sobre todas las oraciones y palabras en inglés e imprime la información de las palabras una por una:\n"
      ],
      "metadata": {
        "id": "31YCX4bZ4s8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sent in enumerate(doc.sentences):\n",
        "    print(\"[Sentence {}]\".format(i+1))\n",
        "    for word in sent.words:\n",
        "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{:d}\\t{:12s}\".format(\\\n",
        "              word.text, word.lemma, word.pos, word.head, word.deprel))\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAeBQq8h6mMH",
        "outputId": "7f589cce-73e0-4cf8-c9f7-47465f07d858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Sentence 1]\n",
            "Jane        \tJane        \tPROPN \t2\tnsubj       \n",
            "bought      \tbuy         \tVERB  \t0\troot        \n",
            "me          \tI           \tPRON  \t2\tiobj        \n",
            "these       \tthis        \tDET   \t5\tdet         \n",
            "books       \tbook        \tNOUN  \t2\tobj         \n",
            ",           \t,           \tPUNCT \t2\tpunct       \n",
            "Jane        \tJane        \tPROPN \t8\tnsubj       \n",
            "bought      \tbuy         \tVERB  \t2\tparataxis   \n",
            "a           \ta           \tDET   \t10\tdet         \n",
            "book        \tbook        \tNOUN  \t8\tobj         \n",
            "for         \tfor         \tADP   \t12\tcase        \n",
            "me          \tI           \tPRON  \t8\tobl         \n",
            ",           \t,           \tPUNCT \t2\tpunct       \n",
            "She         \tshe         \tPRON  \t15\tnsubj       \n",
            "dropped     \tdrop        \tVERB  \t2\tparataxis   \n",
            "a           \ta           \tDET   \t17\tdet         \n",
            "line        \tline        \tNOUN  \t15\tobj         \n",
            "to          \tto          \tADP   \t19\tcase        \n",
            "him         \the          \tPRON  \t15\tobl         \n",
            ".           \t.           \tPUNCT \t2\tpunct       \n",
            "\n",
            "[Sentence 2]\n",
            "Thank       \tthank       \tVERB  \t0\troot        \n",
            "you         \tyou         \tPRON  \t1\tobj         \n",
            ",           \t,           \tPUNCT \t1\tpunct       \n",
            "She         \tshe         \tPRON  \t5\tnsubj       \n",
            "sleeps      \tsleep       \tVERB  \t1\tparataxis   \n",
            ",           \t,           \tPUNCT \t8\tpunct       \n",
            "I           \tI           \tPRON  \t8\tnsubj       \n",
            "sleep       \tsleep       \tVERB  \t1\tparataxis   \n",
            "a           \ta           \tDET   \t10\tdet         \n",
            "lot         \tlot         \tNOUN  \t8\tobl:npmod   \n",
            ",           \t,           \tPUNCT \t1\tpunct       \n",
            "I           \tI           \tPRON  \t14\tnsubj:pass  \n",
            "was         \tbe          \tAUX   \t14\taux:pass    \n",
            "born        \tbear        \tVERB  \t1\tparataxis   \n",
            "in          \tin          \tADP   \t16\tcase        \n",
            "Madrid      \tMadrid      \tPROPN \t14\tobl         \n",
            ",           \t,           \tPUNCT \t1\tpunct       \n",
            "the         \tthe         \tDET   \t19\tdet         \n",
            "cat         \tcat         \tNOUN  \t21\tnsubj:pass  \n",
            "was         \tbe          \tAUX   \t21\taux:pass    \n",
            "chased      \tchase       \tVERB  \t1\tparataxis   \n",
            "by          \tby          \tADP   \t24\tcase        \n",
            "the         \tthe         \tDET   \t24\tdet         \n",
            "dog         \tdog         \tNOUN  \t21\tobl:agent   \n",
            ",           \t,           \tPUNCT \t1\tpunct       \n",
            "I           \tI           \tPRON  \t28\tnsubj:pass  \n",
            "was         \tbe          \tAUX   \t28\taux:pass    \n",
            "born        \tbear        \tVERB  \t1\tparataxis   \n",
            "in          \tin          \tADP   \t30\tcase        \n",
            "Madrid      \tMadrid      \tPROPN \t28\tobl         \n",
            "during      \tduring      \tADP   \t32\tcase        \n",
            "1995        \t1995        \tNUM   \t28\tobl         \n",
            ",           \t,           \tPUNCT \t1\tpunct       \n",
            "Out         \tout         \tADP   \t37\tcase        \n",
            "of          \tof          \tADP   \t34\tfixed       \n",
            "all         \tall         \tDET   \t37\tdet:predet  \n",
            "this        \tthis        \tPRON  \t42\tobl         \n",
            ",           \t,           \tPUNCT \t1\tpunct       \n",
            "something   \tsomething   \tPRON  \t42\tnsubj       \n",
            "good        \tgood        \tADJ   \t39\tamod        \n",
            "will        \twill        \tAUX   \t42\taux         \n",
            "come        \tcome        \tVERB  \t1\tparataxis   \n",
            ",           \t,           \tPUNCT \t1\tpunct       \n",
            "Susan       \tSusan       \tPROPN \t45\tnsubj       \n",
            "left        \tleave       \tVERB  \t1\tparataxis   \n",
            "after       \tafter       \tADP   \t48\tcase        \n",
            "the         \tthe         \tDET   \t48\tdet         \n",
            "rehearsal   \trehearsal   \tNOUN  \t45\tobl         \n",
            ".           \t.           \tPUNCT \t1\tpunct       \n",
            "\n",
            "[Sentence 3]\n",
            "She         \tshe         \tPRON  \t2\tnsubj       \n",
            "did         \tdo          \tVERB  \t0\troot        \n",
            "it          \tit          \tPRON  \t2\tobj         \n",
            "well        \twell        \tADV   \t2\tadvmod      \n",
            ",           \t,           \tPUNCT \t2\tpunct       \n",
            "She         \tshe         \tPRON  \t7\tnsubj       \n",
            "sleeps      \tsleep       \tVERB  \t2\tparataxis   \n",
            "during      \tduring      \tADP   \t10\tcase        \n",
            "the         \tthe         \tDET   \t10\tdet         \n",
            "morning     \tmorning     \tNOUN  \t7\tobl         \n",
            ",           \t,           \tPUNCT \t14\tpunct       \n",
            "but         \tbut         \tCCONJ \t14\tcc          \n",
            "she         \tshe         \tPRON  \t14\tnsubj       \n",
            "sleeps      \tsleep       \tVERB  \t2\tconj        \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5691SpFHFZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d19ccab-6065-4d71-8861-0daf45f3a158"
      },
      "source": [
        "for i, sent in enumerate(en_doc.sentences):\n",
        "    print(\"[Sentence {}]\".format(i+1))\n",
        "    for word in sent.words:\n",
        "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{:d}\\t{:12s}\".format(\\\n",
        "              word.text, word.lemma, word.pos, word.head, word.deprel))\n",
        "    print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Sentence 1]\n",
            "Barack      \tBarack      \tPROPN \t4\tnsubj:pass  \n",
            "Obama       \tObama       \tPROPN \t1\tflat        \n",
            "was         \tbe          \tAUX   \t4\taux:pass    \n",
            "born        \tbear        \tVERB  \t0\troot        \n",
            "in          \tin          \tADP   \t6\tcase        \n",
            "Hawaii      \tHawaii      \tPROPN \t4\tobl         \n",
            ".           \t.           \tPUNCT \t4\tpunct       \n",
            "\n",
            "[Sentence 2]\n",
            "He          \the          \tPRON  \t3\tnsubj:pass  \n",
            "was         \tbe          \tAUX   \t3\taux:pass    \n",
            "elected     \telect       \tVERB  \t0\troot        \n",
            "president   \tpresident   \tNOUN  \t3\txcomp       \n",
            "in          \tin          \tADP   \t6\tcase        \n",
            "2008        \t2008        \tNUM   \t3\tobl         \n",
            ".           \t.           \tPUNCT \t3\tpunct       \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AUkCkNIrusq"
      },
      "source": [
        "The following example iterate over all extracted named entity mentions and print out their character spans and types."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mention text\\tType\\tStart-End\")\n",
        "for ent in doc.ents:\n",
        "    print(\"{}\\t{}\\t{}-{}\".format(ent.text, ent.type, ent.start_char, ent.end_char))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxRSUE8l6tn3",
        "outputId": "ab219779-44ae-4c25-90ad-b4236e0b133e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mention text\tType\tStart-End\n",
            "Jane\tPERSON\t0-4\n",
            "Jane\tPERSON\t27-31\n",
            "Madrid\tGPE\t130-136\n",
            "Madrid\tGPE\t181-187\n",
            "1995\tDATE\t195-199\n",
            "Susan\tPERSON\t243-248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Uu0-WmvsnlK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988ba78a-4c04-4390-fdbe-96068a0b5fe5"
      },
      "source": [
        "print(\"Mention text\\tType\\tStart-End\")\n",
        "for ent in en_doc.ents:\n",
        "    print(\"{}\\t{}\\t{}-{}\".format(ent.text, ent.type, ent.start_char, ent.end_char))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mention text\tType\tStart-End\n",
            "Barack Obama\tPERSON\t0-12\n",
            "Hawaii\tGPE\t25-31\n",
            "2008\tDATE\t62-66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql1SZlZOnMLo"
      },
      "source": [
        "And similarly for the Chinese text:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sent in enumerate(zh_doc.sentences):\n",
        "    print(\"[Sentence {}]\".format(i+1))\n",
        "    for word in sent.words:\n",
        "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{:d}\\t{:12s}\".format(\\\n",
        "              word.text, word.lemma, word.pos, word.head, word.deprel))\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRc2HJl16x7d",
        "outputId": "aaa7a8fe-d403-4634-8970-a5c5c1a96618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Sentence 1]\n",
            "达沃斯         \t达沃斯         \tPROPN \t4\tnmod        \n",
            "世界          \t世界          \tNOUN  \t4\tnmod        \n",
            "经济          \t经济          \tNOUN  \t4\tnmod        \n",
            "论坛          \t论坛          \tNOUN  \t16\tnsubj       \n",
            "是           \t是           \tAUX   \t16\tcop         \n",
            "每年          \t每年          \tDET   \t10\tdet         \n",
            "全球          \t全球          \tNOUN  \t10\tnmod        \n",
            "政商          \t政商          \tNOUN  \t9\tcompound    \n",
            "界           \t界           \tPART  \t10\tnmod        \n",
            "领袖          \t领袖          \tNOUN  \t11\tnsubj       \n",
            "聚           \t聚           \tVERB  \t16\tacl:relcl   \n",
            "在           \t在           \tVERB  \t11\tmark        \n",
            "一起          \t一起          \tNOUN  \t11\tobj         \n",
            "的           \t的           \tPART  \t11\tmark:rel    \n",
            "年度          \t年度          \tNOUN  \t16\tnmod        \n",
            "盛事          \t盛事          \tNOUN  \t0\troot        \n",
            "。           \t。           \tPUNCT \t16\tpunct       \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsVcEO9tHKPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c587706-179e-41da-849c-f5da8a64ecfd"
      },
      "source": [
        "for i, sent in enumerate(zh_doc.sentences):\n",
        "    print(\"[Sentence {}]\".format(i+1))\n",
        "    for word in sent.words:\n",
        "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{:d}\\t{:12s}\".format(\\\n",
        "              word.text, word.lemma, word.pos, word.head, word.deprel))\n",
        "    print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Sentence 1]\n",
            "达沃斯         \t达沃斯         \tPROPN \t4\tnmod        \n",
            "世界          \t世界          \tNOUN  \t4\tnmod        \n",
            "经济          \t经济          \tNOUN  \t4\tnmod        \n",
            "论坛          \t论坛          \tNOUN  \t16\tnsubj       \n",
            "是           \t是           \tAUX   \t16\tcop         \n",
            "每年          \t每年          \tDET   \t10\tdet         \n",
            "全球          \t全球          \tNOUN  \t10\tnmod        \n",
            "政商          \t政商          \tNOUN  \t9\tcompound    \n",
            "界           \t界           \tPART  \t10\tnmod        \n",
            "领袖          \t领袖          \tNOUN  \t11\tnsubj       \n",
            "聚           \t聚           \tVERB  \t16\tacl:relcl   \n",
            "在           \t在           \tVERB  \t11\tmark        \n",
            "一起          \t一起          \tNOUN  \t11\tobj         \n",
            "的           \t的           \tPART  \t11\tmark:rel    \n",
            "年度          \t年度          \tNOUN  \t16\tnmod        \n",
            "盛事          \t盛事          \tNOUN  \t0\troot        \n",
            "。           \t。           \tPUNCT \t16\tpunct       \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUhWAs8pnnHT"
      },
      "source": [
        "Alternatively, you can directly print a `Word` object to view all its annotations as a Python dict:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = doc.sentences[0].words[0]\n",
        "print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS6PW54c61_l",
        "outputId": "02abda57-5b34-4120-d851-8ab99a3d67f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": 1,\n",
            "  \"text\": \"Jane\",\n",
            "  \"lemma\": \"Jane\",\n",
            "  \"upos\": \"PROPN\",\n",
            "  \"xpos\": \"NNP\",\n",
            "  \"feats\": \"Number=Sing\",\n",
            "  \"head\": 2,\n",
            "  \"deprel\": \"nsubj\",\n",
            "  \"start_char\": 0,\n",
            "  \"end_char\": 4\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_UafNb7HHIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638d58c5-7758-4b80-895e-373a7d128378"
      },
      "source": [
        "word = en_doc.sentences[1].words[1]\n",
        "print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": 2,\n",
            "  \"text\": \"was\",\n",
            "  \"lemma\": \"be\",\n",
            "  \"upos\": \"AUX\",\n",
            "  \"xpos\": \"VBD\",\n",
            "  \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
            "  \"head\": 3,\n",
            "  \"deprel\": \"aux:pass\",\n",
            "  \"start_char\": 37,\n",
            "  \"end_char\": 40\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAQlOsuRoq2V"
      },
      "source": [
        "### More Information\n",
        "\n",
        "For all information on different data objects, please visit our [data objects page](https://stanfordnlp.github.io/stanza/data_objects.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información\n",
        "Para obtener toda la información sobre los diferentes objetos de datos, visite nuestra página de objetos de datos.\n",
        "Envia"
      ],
      "metadata": {
        "id": "_aEtIy-z43gd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiiWHxYPpmhd"
      },
      "source": [
        "## 5. Resources\n",
        "\n",
        "Apart from this interactive tutorial, we also provide tutorials on our website that cover a variety of use cases such as how to use different model \"packages\" for a language, how to use spaCy as a tokenizer, how to process pretokenized text without running the tokenizer, etc. For these tutorials please visit [our Tutorials page](https://stanfordnlp.github.io/stanza/tutorials.html).\n",
        "\n",
        "Other resources that you may find helpful include:\n",
        "\n",
        "- [Stanza Homepage](https://stanfordnlp.github.io/stanza/index.html)\n",
        "- [FAQs](https://stanfordnlp.github.io/stanza/faq.html)\n",
        "- [GitHub Repo](https://github.com/stanfordnlp/stanza)\n",
        "- [Reporting Issues](https://github.com/stanfordnlp/stanza/issues)\n",
        "- [Stanza System Description Paper](http://arxiv.org/abs/2003.07082)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Recursos**\n",
        "Además de este tutorial interactivo, también ofrecemos tutoriales en nuestro sitio web que cubren una variedad de casos de uso, como cómo usar diferentes \"paquetes\" de modelos para un lenguaje, cómo usar spaCy como tokenizador, cómo procesar texto pretokenizado sin ejecutar el tokenizador, etc. Para ver estos tutoriales, visite nuestra página de Tutoriales.\n",
        "\n",
        "Otros recursos que pueden resultarle útiles incluyen:\n",
        "\n",
        "Página de inicio de Stanza\n",
        "Preguntas frecuentes\n",
        "Repositorio de GitHub\n",
        "Informar problemas\n",
        "Documento de descripción del sistema de Stanza"
      ],
      "metadata": {
        "id": "5_wKEiIE5O68"
      }
    }
  ]
}